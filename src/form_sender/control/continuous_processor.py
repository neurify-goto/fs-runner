"""
é€£ç¶šå‡¦ç†åˆ¶å¾¡

5æ™‚é–“åˆ¶é™ã€å–¶æ¥­æ™‚é–“ã€æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™ç­‰ã®åˆ¶å¾¡æ©Ÿèƒ½
"""

import json
import logging
import os
import tempfile
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, Optional, Tuple, List

from supabase import create_client

from ..database.manager import DatabaseManager
from ..template.company_processor import CompanyPlaceholderAnalyzer

logger = logging.getLogger(__name__)


class ContinuousProcessController:
    """é€£ç¶šå‡¦ç†åˆ¶å¾¡ã‚¯ãƒ©ã‚¹ï¼ˆæ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç”¨ï¼‰"""
    
    def __init__(self, targeting_id: int, max_execution_time: int = 5 * 60 * 60):
        self.targeting_id = targeting_id
        self.max_execution_time = max_execution_time  # 5æ™‚é–“åˆ¶é™
        self.start_time = time.time()
        self.processed_count = 0
        self.success_count = 0
        self.failed_count = 0
        self.supabase_client = None
        self.db_manager = None
        
        # FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : å¤§é‡å–å¾—+ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†æ–¹å¼
        self.temp_companies_file = None
        self.companies_buffer = []  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ä¼æ¥­ãƒãƒƒãƒ•ã‚¡
        
        # å‹•çš„MAX_COMPANY_IDã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._max_record_id_cache = None
        self._max_record_id_cache_time = 0
        self._max_record_id_cache_duration = 24 * 60 * 60  # 24æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # è¨­å®šå€¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šç”¨ï¼‰
        self._validated_config_cache = None
        self._config_cache_key = None
        
    def initialize_supabase(self):
        """SupabaseåˆæœŸåŒ–"""
        supabase_url = os.getenv('SUPABASE_URL')
        supabase_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        
        if not supabase_url or not supabase_key:
            raise ValueError("Supabase credentials not found")
        
        self.supabase_client = create_client(supabase_url, supabase_key)
        self.db_manager = DatabaseManager(self.supabase_client)
    
    def _get_config_value(self, config: Dict[str, Any], key: str, fallback_key: str = None) -> Any:
        """
        2ã‚·ãƒ¼ãƒˆæ§‹é€ ã¨ãƒ•ãƒ©ãƒƒãƒˆæ§‹é€ ä¸¡å¯¾å¿œã®è¨­å®šå€¤å–å¾—
        
        Args:
            config: è¨­å®šãƒ‡ãƒ¼ã‚¿
            key: å–å¾—ã™ã‚‹ã‚­ãƒ¼
            fallback_key: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚­ãƒ¼
        
        Returns:
            è¨­å®šå€¤ã¾ãŸã¯None
        """
        # ãƒ•ãƒ©ãƒƒãƒˆæ§‹é€ ã§ã®å–å¾—ã‚’è©¦è¡Œ
        if key in config:
            return config[key]
        
        # 2ã‚·ãƒ¼ãƒˆæ§‹é€ ã§ã®å–å¾—ã‚’è©¦è¡Œ
        if 'targeting' in config and key in config['targeting']:
            return config['targeting'][key]
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if fallback_key and fallback_key in config:
            return config[fallback_key]
            
        return None
    
    def _validate_and_cache_config(self, client_config: Dict[str, Any]) -> Dict[str, Any]:
        """è¨­å®šå€¤ã‚’æ¤œè¨¼ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è¿”ã™ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆè¨­å®šå†…å®¹ã®ãƒãƒƒã‚·ãƒ¥ï¼‰
        import hashlib
        config_str = json.dumps(client_config, sort_keys=True)
        cache_key = hashlib.md5(config_str.encode()).hexdigest()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã¯æ¤œè¨¼æ¸ˆã¿è¨­å®šã‚’è¿”ã™
        if self._config_cache_key == cache_key and self._validated_config_cache:
            return self._validated_config_cache
        
        # å–¶æ¥­æ—¥è¨­å®šã®æ¤œè¨¼ï¼ˆ2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
        send_days = self._get_config_value(client_config, 'send_days_of_week')
        if send_days is None:
            error_msg = "å–¶æ¥­æ—¥è¨­å®š(send_days_of_week)ãŒclient_configã«å­˜åœ¨ã—ã¾ã›ã‚“"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        if isinstance(send_days, str):
            try:
                send_days = json.loads(send_days)
            except json.JSONDecodeError:
                error_msg = f"å–¶æ¥­æ—¥è¨­å®š(send_days_of_week)ã®å½¢å¼ãŒä¸æ­£ã§ã™: {send_days}"
                logger.error(error_msg)
                raise ValueError(error_msg)
                
        if not isinstance(send_days, list) or not all(isinstance(day, int) and 0 <= day <= 6 for day in send_days):
            error_msg = f"å–¶æ¥­æ—¥è¨­å®š(send_days_of_week)ã¯0-6ã®æ•´æ•°ãƒªã‚¹ãƒˆã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {send_days}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # å–¶æ¥­æ™‚é–“è¨­å®šã®æ¤œè¨¼ï¼ˆ2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
        start_time_str = self._get_config_value(client_config, 'send_start_time')
        if start_time_str is None:
            error_msg = "å–¶æ¥­é–‹å§‹æ™‚é–“è¨­å®š(send_start_time)ãŒclient_configã«å­˜åœ¨ã—ã¾ã›ã‚“"
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        end_time_str = self._get_config_value(client_config, 'send_end_time')
        if end_time_str is None:
            error_msg = "å–¶æ¥­çµ‚äº†æ™‚é–“è¨­å®š(send_end_time)ãŒclient_configã«å­˜åœ¨ã—ã¾ã›ã‚“"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        def parse_time_to_minutes(time_str: str, field_name: str) -> int:
            """æ™‚é–“æ–‡å­—åˆ—ï¼ˆHH:MMï¼‰ã‚’åˆ†ã«å¤‰æ›"""
            try:
                hours, minutes = time_str.split(':')
                hour_int = int(hours)
                minute_int = int(minutes)
                
                if not (0 <= hour_int <= 23):
                    raise ValueError(f"æ™‚é–“ã¯0-23ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {hour_int}")
                if not (0 <= minute_int <= 59):
                    raise ValueError(f"åˆ†ã¯0-59ã®ç¯„å›²ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {minute_int}")
                    
                return hour_int * 60 + minute_int
            except (ValueError, IndexError) as e:
                error_msg = f"{field_name}ã®å½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆHH:MMå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰: {time_str}, ã‚¨ãƒ©ãƒ¼: {e}"
                logger.error(error_msg)
                raise ValueError(error_msg)
        
        start_time_minutes = parse_time_to_minutes(start_time_str, "å–¶æ¥­é–‹å§‹æ™‚é–“(send_start_time)")
        end_time_minutes = parse_time_to_minutes(end_time_str, "å–¶æ¥­çµ‚äº†æ™‚é–“(send_end_time)")
        
        # å–¶æ¥­æ™‚é–“ã®è«–ç†ãƒã‚§ãƒƒã‚¯
        if start_time_minutes >= end_time_minutes:
            error_msg = f"å–¶æ¥­é–‹å§‹æ™‚é–“ã¯çµ‚äº†æ™‚é–“ã‚ˆã‚Šå‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: é–‹å§‹={start_time_str}, çµ‚äº†={end_time_str} (æ·±å¤œå–¶æ¥­ã¯ç¾åœ¨å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“)"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™ã®æ¤œè¨¼ï¼ˆ2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
        max_daily = self._get_config_value(client_config, 'max_daily_sends')
        if max_daily is None:
            error_msg = "æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™è¨­å®š(max_daily_sends)ãŒclient_configã«å­˜åœ¨ã—ã¾ã›ã‚“"
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        try:
            max_daily = int(max_daily)
            if max_daily <= 0:
                error_msg = f"æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™(max_daily_sends)ã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {max_daily}"
                logger.error(error_msg)
                raise ValueError(error_msg)
            if max_daily > 50000:
                error_msg = f"æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™(max_daily_sends)ã¯ç¾å®Ÿçš„ãªç¯„å›²å†…ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆä¸Šé™: 50,000ä»¶/æ—¥ï¼‰: {max_daily}"
                logger.error(error_msg)
                raise ValueError(error_msg)
        except (ValueError, TypeError) as e:
            error_msg = f"æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™(max_daily_sends)ã®å½¢å¼ãŒä¸æ­£ã§ã™: {max_daily}, ã‚¨ãƒ©ãƒ¼: {e}"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # æ¤œè¨¼æ¸ˆã¿è¨­å®šã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        validated_config = {
            'send_days_of_week': send_days,
            'send_start_time': start_time_str,
            'send_end_time': end_time_str,
            'start_time_minutes': start_time_minutes,
            'end_time_minutes': end_time_minutes,
            'max_daily_sends': max_daily
        }
        
        self._validated_config_cache = validated_config
        self._config_cache_key = cache_key
        
        return validated_config
        
    def _get_max_record_id(self) -> int:
        """companiesãƒ†ãƒ¼ãƒ–ãƒ«ã®æœ€å¤§IDã‚’å‹•çš„å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
        try:
            current_time = time.time()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ãã‚Œã‚’è¿”ã™
            if (self._max_record_id_cache is not None and 
                current_time - self._max_record_id_cache_time < self._max_record_id_cache_duration):
                logger.debug(f"Using cached max record ID: {self._max_record_id_cache}")
                return self._max_record_id_cache
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€å¤§IDã‚’å–å¾—
            def get_max_id():
                return self.supabase_client.table('companies') \
                    .select('id') \
                    .order('id', desc=True) \
                    .limit(1) \
                    .execute()
            
            response = self.db_manager.execute_with_retry_sync(
                f"get_max_record_id_targeting_{self.targeting_id}",
                get_max_id
            )
            
            if response.data and len(response.data) > 0:
                max_id = response.data[0]['id']
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
                self._max_record_id_cache = max_id
                self._max_record_id_cache_time = current_time
                logger.info(f"Updated max company ID cache: {max_id}")
                return max_id
            else:
                # ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ä½¿ç”¨
                fallback_max_id = 536156
                logger.warning(f"Could not get max company ID from database, using fallback: {fallback_max_id}")
                return fallback_max_id
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ä½¿ç”¨
            fallback_max_id = 536156
            logger.error(f"Error getting max company ID: {e}, using fallback: {fallback_max_id}")
            return fallback_max_id
    
    def _apply_unified_filters(self, companies: List[Dict[str, Any]], client_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """RPCãƒ»åŸºæœ¬ã‚¯ã‚¨ãƒªå…±é€šã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆçµ±ä¸€åŒ–ï¼‰"""
        try:
            if not companies:
                return companies
            
            # 1. ng_companiesæ­£è¦è¡¨ç¾é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
            ng_companies = self._get_config_value(client_config, 'ng_companies', '') or ''
            ng_companies = ng_companies.strip()
            if ng_companies:
                ng_pattern = ng_companies.replace(',', '|').replace('ï¼Œ', '|')
                import re
                try:
                    ng_regex = re.compile(ng_pattern, re.IGNORECASE)
                    companies = [c for c in companies if not ng_regex.search(c.get('name', ''))]
                    logger.debug(f"Applied ng_companies filter, remaining: {len(companies)}")
                except re.error as e:
                    logger.warning(f"Invalid ng_companies regex pattern '{ng_pattern}': {e}")
            
            # 2. instruction_validæ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¾“æ¥ã®æŒ‡ç¤ºæ›¸æœ‰ç„¡ã«ä¾å­˜ã—ãªã„ï¼‰
            companies = [c for c in companies if c.get('instruction_valid') is not False]
            
            # 3. å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯ï¼ˆinstruction_jsonã¯å»ƒæ­¢ã®ãŸã‚ä¸è¦ï¼‰
            companies = [c for c in companies if c.get('form_url')]
            
            logger.debug(f"Applied unified filters, final count: {len(companies)}")
            return companies
            
        except Exception as e:
            logger.error(f"Error applying unified filters: {e}")
            return companies  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒªã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
    
    def _validate_targeting_sql_client_side(self, targeting_sql: str) -> bool:
        """ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã€‘ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰äº‹å‰æ¤œè¨¼"""
        try:
            if not targeting_sql or not targeting_sql.strip():
                return True  # ç©ºæ–‡å­—ã¯æœ‰åŠ¹
            
            sql_upper = targeting_sql.upper()
            
            # å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®äº‹å‰æ¤œå‡ºï¼ˆæ‹¡å¼µç‰ˆï¼‰
            dangerous_patterns = [
                'DROP', 'DELETE', 'UPDATE', 'INSERT', 'CREATE', 'ALTER',
                'EXEC', 'EXECUTE', 'UNION', 'SCRIPT', 'DECLARE', 'TRUNCATE',
                'GRANT', 'REVOKE', 'SET', 'RESET', '--', ';', '/*', '*/',
                # SQLæ³¨å…¥ã®å…¸å‹çš„ãƒ‘ã‚¿ãƒ¼ãƒ³
                "' OR '", '" OR "', '1=1', '1 = 1',
                # æ¡ä»¶ã‚’å¸¸ã«trueã«ã™ã‚‹æ”»æ’ƒ
                "'='", '"="', 'OR 1', 'OR TRUE',
            ]
            
            for pattern in dangerous_patterns:
                if pattern in sql_upper:
                    logger.warning(f"Client-side validation: dangerous pattern detected: {pattern}")
                    return False
            
            # é•·ã•åˆ¶é™ï¼ˆRPCå´ã¨åŒã˜åˆ¶é™ã‚’é©ç”¨ï¼‰
            if len(targeting_sql) > 2000:
                logger.warning(f"Client-side validation: input too long ({len(targeting_sql)} chars)")
                return False
                
            return True
            
        except Exception as e:
            logger.error(f"Error in client-side validation: {e}")
            return False  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å®‰å…¨å´ã«å€’ã™

    def _call_get_target_companies_rpc(self, targeting_sql: str, ng_companies: str, start_id: int, limit: int, exclude_ids: set) -> List[Dict[str, Any]]:
        """æ–°ã—ã„RPCé–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆï¼‰"""
        try:
            # ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ã€‘ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚µã‚¤ãƒ‰äº‹å‰æ¤œè¨¼
            if not self._validate_targeting_sql_client_side(targeting_sql):
                raise ValueError(f"Client-side validation failed for targeting_sql: potentially unsafe content detected")
            
            # ng_companies ã®åŸºæœ¬çš„ãªäº‹å‰æ¤œè¨¼
            if ng_companies and len(ng_companies) > 500:
                raise ValueError(f"ng_companies too long: {len(ng_companies)} chars (max 500)")
            
            # exclude_ids ã‚’é…åˆ—ã«å¤‰æ›
            exclude_ids_array = list(exclude_ids) if exclude_ids else None
            
            logger.info("ğŸ›¡ï¸ Client-side security validation passed")
            
            # RPCé–¢æ•°ã‚’å®Ÿè¡Œ
            response = self.supabase_client.rpc('get_target_companies_with_sql', {
                'targeting_sql': targeting_sql,
                'ng_companies': ng_companies,
                'start_id': start_id,
                'limit_count': limit,
                'exclude_ids': exclude_ids_array
            }).execute()
            
            if response.data is None:
                logger.warning("RPC function returned null data")
                return []
                
            companies = response.data
            logger.info(f"RPC function returned {len(companies)} companies")
            
            return companies
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼åˆ†é¡ã®è©³ç´°åŒ–
            error_msg = str(e).lower()
            if 'network' in error_msg or 'connection' in error_msg:
                logger.error(f"Network error calling RPC: {e}")
                raise ValueError(f"Network error: Unable to connect to database") from e
            elif 'invalid targeting_sql' in error_msg:
                logger.error(f"SQL validation error: {e}")
                raise ValueError(f"Invalid SQL condition: {e}") from e
            elif 'permission' in error_msg or 'auth' in error_msg:
                logger.error(f"Permission error calling RPC: {e}")
                raise ValueError(f"Permission denied: Check database access rights") from e
            else:
                logger.error(f"Unknown error calling get_target_companies_with_sql RPC: {e}")
                raise ValueError(f"Database operation failed: {e}") from e
    
    def _get_companies_using_rpc(self, client_config: Dict[str, Any], start_id: int, limit: int, exclude_ids: set) -> List[Dict[str, Any]]:
        """RPCé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆç›´æ¥SQL WHEREå¥å®Ÿè¡Œï¼‰"""
        try:
            # è¨­å®šå€¤ã‚’å–å¾—
            targeting_sql = self._get_config_value(client_config, 'targeting_sql', '') or ''
            ng_companies = self._get_config_value(client_config, 'ng_companies', '') or ''
            
            logger.info(f"=== RPC FUNCTION CALL ===")
            logger.info(f"targeting_sql: '{targeting_sql}'")
            logger.info(f"ng_companies: '{ng_companies}'")
            logger.info(f"start_id: {start_id}")
            logger.info(f"limit: {limit}")
            logger.info(f"exclude_ids: {len(exclude_ids)} items")
            
            # RPCé–¢æ•°ã‚’å‘¼ã³å‡ºã—
            companies = self._call_get_target_companies_rpc(
                targeting_sql=targeting_sql.strip(),
                ng_companies=ng_companies.strip(),
                start_id=start_id,
                limit=limit,
                exclude_ids=exclude_ids
            )
            
            logger.info(f"=== RPC FUNCTION SUCCESS ===")
            logger.info(f"Retrieved {len(companies)} companies")
            
            return companies
            
        except Exception as e:
            logger.error(f"Critical error using RPC function: {e}")
            raise ValueError(f"Failed to get companies using RPC: {e}") from e


        
    def is_within_time_limit(self) -> bool:
        """5æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯"""
        elapsed = time.time() - self.start_time
        return elapsed < self.max_execution_time
        
    def is_within_business_hours(self, client_config: Dict[str, Any]) -> bool:
        """å–¶æ¥­æ™‚é–“ãƒã‚§ãƒƒã‚¯ï¼ˆFORM_SENDER.md 168-205ä»•æ§˜æº–æ‹ ï¼‰"""
        try:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ¤œè¨¼æ¸ˆã¿è¨­å®šã‚’å–å¾—
            validated_config = self._validate_and_cache_config(client_config)
            
            # JSTæ™‚åˆ»ã‚’æ­£ç¢ºã«è¨ˆç®—
            jst = timezone(timedelta(hours=9))
            now_jst = datetime.now(jst)
            
            # æ›œæ—¥ãƒã‚§ãƒƒã‚¯ï¼ˆ0=æœˆæ›œæ—¥, 1=ç«æ›œæ—¥, ..., 6=æ—¥æ›œæ—¥ï¼‰
            current_day_of_week = now_jst.weekday()
            
            # å–¶æ¥­æ—¥ãƒã‚§ãƒƒã‚¯ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ï¼‰
            send_days = validated_config['send_days_of_week']
            if current_day_of_week not in send_days:
                logger.info(f"Outside business days: current={current_day_of_week}, allowed={send_days}")
                return False
            
            # æ™‚é–“å¸¯ãƒã‚§ãƒƒã‚¯ï¼ˆåˆ†å˜ä½ã§æ­£ç¢ºã«ï¼‰
            current_hour = now_jst.hour
            current_minute = now_jst.minute
            current_time_minutes = current_hour * 60 + current_minute
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ã®æ™‚é–“è¨­å®šã‚’ä½¿ç”¨
            start_time_minutes = validated_config['start_time_minutes']
            end_time_minutes = validated_config['end_time_minutes']
            start_time_str = validated_config['send_start_time']
            end_time_str = validated_config['send_end_time']
            
            is_within_time = start_time_minutes <= current_time_minutes <= end_time_minutes
            
            logger.info(f"Business hours check: current={current_hour:02d}:{current_minute:02d} JST, "
                       f"business={start_time_str}-{end_time_str}, within_hours={is_within_time}")
            
            return is_within_time
            
        except ValueError:
            # è¨­å®šä¸å‚™ã«ã‚ˆã‚‹ValueErrorã¯å†raiseã—ã¦å‡¦ç†ã‚’åœæ­¢
            raise
        except Exception as e:
            # ã‚·ã‚¹ãƒ†ãƒ ä¾‹å¤–ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ç­‰ï¼‰ã¯å‡¦ç†ç¶™ç¶š
            logger.error(f"Business hours check system error: {e}")
            return True  # ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼æ™‚ã®ã¿ç¶™ç¶šï¼ˆå®‰å…¨å´ã«å€’ã™ï¼‰
    
    def get_today_success_count(self) -> int:
        """ä»Šæ—¥ã®é€ä¿¡æˆåŠŸæ•°ã‚’å–å¾—ï¼ˆJSTåŸºæº–ï¼‰"""
        try:
            # JSTæ™‚åˆ»ã§ä»Šæ—¥ã®ç¯„å›²ã‚’è¨ˆç®—
            jst = timezone(timedelta(hours=9))
            now_jst = datetime.now(jst)
            today_jst = now_jst.date()
            
            # ä»Šæ—¥ã®JSTæ—¥ä»˜ã§ç¯„å›²ã‚’è¨­å®š
            start_of_day = f'{today_jst.isoformat()}T00:00:00+09:00'
            end_of_day = f'{today_jst.isoformat()}T23:59:59+09:00'
            
            # å†è©¦è¡Œæ©Ÿèƒ½ä»˜ãã§DBå•ã„åˆã‚ã›
            def get_success_count():
                response = self.supabase_client.table('submissions') \
                    .select('id') \
                    .eq('targeting_id', self.targeting_id) \
                    .eq('success', True) \
                    .gte('submitted_at', start_of_day) \
                    .lte('submitted_at', end_of_day) \
                    .execute()
                return response
            
            response = self.db_manager.execute_with_retry_sync(
                f"get_today_success_count_targeting_{self.targeting_id}",
                get_success_count
            )
            
            count = len(response.data) if response.data else 0
            # Targeting IDã¯éè¡¨ç¤º
            logger.info(f"Today's success count: {count}")
            
            return count
            
        except Exception as e:
            logger.error(f"Error getting today's success count (all retries failed): {e}")
            return 0  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯0ã‚’è¿”ã—ã¦å®‰å…¨å´ã«å€’ã™
    
    def is_within_daily_limit(self, max_daily_sends: int) -> bool:
        """æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯"""
        today_count = self.get_today_success_count()
        return today_count < max_daily_sends
    
    def save_result_immediately(self, record_id: int, status: str, error_type: Optional[str] = None, instruction_valid_updated: bool = False, bot_protection_detected: bool = False):
        """ä¼æ¥­å‡¦ç†çµæœã‚’å³åº§ã«DBã«ä¿å­˜ï¼ˆFORM_SENDER.md 308-332ä»•æ§˜æº–æ‹ ï¼‰"""
        try:
            # JSTæ™‚åˆ»ã§è¨˜éŒ²
            jst = timezone(timedelta(hours=9))
            now_jst = datetime.now(jst)
            
            # submissionsãƒ†ãƒ¼ãƒ–ãƒ«ã«è¨˜éŒ² (statusã‚«ãƒ©ãƒ ã¯å‰Šé™¤æ¸ˆã¿ã®ãŸã‚é™¤å¤–)
            submission_data = {
                'targeting_id': self.targeting_id,
                'company_id': record_id,
                'success': status == 'success',
                'error_type': error_type,
                'submitted_at': now_jst.isoformat()
            }
            
            # å†è©¦è¡Œæ©Ÿèƒ½ä»˜ãã§DBä¿å­˜
            def insert_submission():
                return self.supabase_client.table('submissions').insert(submission_data).execute()
            
            result = self.db_manager.execute_with_retry_sync(
                f"save_submission_company_{record_id}",
                insert_submission
            )
            
            # bot protectionæ¤œå‡ºæ™‚ã«companiesãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ•ãƒ©ã‚°ã‚’æ›´æ–°
            if bot_protection_detected:
                try:
                    def update_bot_protection():
                        return self.supabase_client.table('companies').update({
                            'bot_protection_detected': True
                        }).eq('id', record_id).execute()
                    
                    self.db_manager.execute_with_retry_sync(
                        f"update_bot_protection_company_{record_id}",
                        update_bot_protection
                    )
                    logger.info(f"Updated bot_protection_detected=true for record_id={record_id}")
                except Exception as e:
                    logger.error(f"Error updating bot_protection_detected for company {record_id}: {e}")
            
            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°
            self.processed_count += 1
            if status == 'success':
                self.success_count += 1
            else:
                self.failed_count += 1
            
            logger.info(f"Saved result: record_id={record_id}, status={status}, "
                       f"error_type={error_type}, processed={self.processed_count}")
            
        except Exception as e:
            logger.error(f"Error saving result immediately (all retries failed): {e}")
            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã¯æ›´æ–°ï¼ˆè¨˜éŒ²å¤±æ•—ã§ã‚‚ãƒ—ãƒ­ã‚»ã‚¹ã¯ç¶™ç¶šï¼‰
            self.processed_count += 1
            if status == 'success':
                self.success_count += 1
            else:
                self.failed_count += 1
    
    # update_instruction_validityå‰Šé™¤ - RuleBasedAnalyzerãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è§£æã§ã¯DBã®instruction_validãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã—ãªã„
    
    def should_continue_processing(self, client_config: Dict[str, Any]) -> Tuple[bool, str]:
        """å‡¦ç†ç¶™ç¶šå¯å¦ã®åˆ¤å®šï¼ˆå–¶æ¥­æ™‚é–“ãƒã‚§ãƒƒã‚¯ã¯workerå´ã§å®Ÿæ–½ï¼‰"""
        # æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not self.is_within_time_limit():
            return False, "æ™‚é–“åˆ¶é™ï¼ˆ5æ™‚é–“ï¼‰ã«åˆ°é”"
            
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰æ¤œè¨¼æ¸ˆã¿è¨­å®šã‚’å–å¾—
        validated_config = self._validate_and_cache_config(client_config)
        
        # æ—¥æ¬¡é€ä¿¡æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ï¼‰
        max_daily = validated_config['max_daily_sends']
        if not self.is_within_daily_limit(max_daily):
            return False, f"æ—¥æ¬¡é€ä¿¡æ•°ä¸Šé™ï¼ˆ{max_daily}ä»¶ï¼‰ã«åˆ°é”"
        
        return True, "ç¶™ç¶šå¯èƒ½"
    
    def _create_bulk_fetch_query(self, client_config: Dict[str, Any]) -> str:
        """FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : å¤§é‡å–å¾—ç”¨SQLã‚¯ã‚¨ãƒªæ§‹ç¯‰ï¼ˆå–¶æ¥­ç¦æ­¢æ¤œå‡ºæ¸ˆã¿ä¼æ¥­é™¤å¤–å¯¾å¿œï¼‰"""
        base_conditions = [
            "c.form_url IS NOT NULL",
            # instruction_json ã¯å»ƒæ­¢ï¼ˆRuleBasedAnalyzerã‚’å¸¸ç”¨ï¼‰
            "(c.instruction_valid IS NULL OR c.instruction_valid = true)",
            "(c.prohibition_detected IS NULL OR c.prohibition_detected = false)"
        ]
        
        # targeting_sqlæ¡ä»¶ã‚’è¿½åŠ ï¼ˆå®‰å…¨æ€§æ¤œè¨¼ä»˜ãã€2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
        targeting_sql = self._get_config_value(client_config, 'targeting_sql', '') or ''
        targeting_sql = targeting_sql.strip()
        if targeting_sql:
            # WHEREå¥ã®é‡è¤‡ã‚’é˜²ããŸã‚ã€WHEREå¥ã‚’é™¤å»
            if targeting_sql.upper().startswith('WHERE '):
                targeting_sql = targeting_sql[6:].strip()
            
            # SQLå®‰å…¨æ€§æ¤œè¨¼ã‚’é©ç”¨
            sanitized_targeting_sql = self._sanitize_sql_conditions(targeting_sql)
            if sanitized_targeting_sql:
                base_conditions.append(f"({sanitized_targeting_sql})")
            else:
                logger.warning("targeting_sql was rejected due to security concerns, ignoring")
        
        # ng_companiesé™¤å¤–å‡¦ç†ï¼ˆFORM_SENDER.md 1.4.2ä»•æ§˜æº–æ‹ ã€å®‰å…¨æ€§å¼·åŒ–ã€2ã‚·ãƒ¼ãƒˆæ§‹é€ å¯¾å¿œï¼‰
        ng_companies = self._get_config_value(client_config, 'ng_companies', '') or ''
        ng_companies = ng_companies.strip()
        if ng_companies:
            # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã‚’ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šã«å¤‰æ›ã—ã¦æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆ
            ng_pattern = ng_companies.replace(',', '|').replace('ï¼Œ', '|')  # å…¨è§’ã‚«ãƒ³ãƒã‚‚å¯¾å¿œ
            
            # ã‚ˆã‚Šå³å¯†ãªå®‰å…¨åŒ–å‡¦ç†
            sanitized_ng_pattern = self._sanitize_sql_conditions(ng_pattern)
            if sanitized_ng_pattern and len(sanitized_ng_pattern) < 1000:  # ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒé•·ã™ããªã„ã‹ãƒã‚§ãƒƒã‚¯
                base_conditions.append(f"c.name !~ '{sanitized_ng_pattern}'")
            else:
                logger.warning("ng_companies pattern was rejected due to security or length concerns, ignoring")
        
        where_clause = " AND ".join(base_conditions)
        logger.debug(f"Bulk fetch query conditions: {len(base_conditions)} conditions including prohibition_detected exclusion")
        return where_clause
    
    def _get_required_company_columns(self, client_config: Dict[str, Any]) -> set:
        """ä¼æ¥­å›ºæœ‰ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«å¿…è¦ãªè¿½åŠ ã‚«ãƒ©ãƒ ã‚’å–å¾—"""
        try:
            required_columns = CompanyPlaceholderAnalyzer.get_required_company_columns(client_config)
            # Targeting IDã¯éè¡¨ç¤º
            logger.info(f"Required company columns: {required_columns}")
            return required_columns
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼è©³ç´°ã¯éè¡¨ç¤º
            logger.error("Error getting required company columns: System error occurred")
            return set()
    
    def _build_select_columns(self, additional_columns: set) -> str:
        """åŸºæœ¬ã‚«ãƒ©ãƒ  + è¿½åŠ ã‚«ãƒ©ãƒ ã§SELECTæ–‡ã‚’æ§‹ç¯‰"""
        # åŸºæœ¬çš„ãªå¿…é ˆã‚«ãƒ©ãƒ ï¼ˆå®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
        base_columns = {
            'id', 'company_name', 'form_url',
            'instruction_valid'
        }
        
        # è¿½åŠ ã‚«ãƒ©ãƒ ã¨çµåˆï¼ˆé‡è¤‡ã‚’è‡ªå‹•é™¤å»ï¼‰
        all_columns = base_columns | additional_columns
        
        # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        select_string = ', '.join(sorted(all_columns))
        logger.debug(f"Select columns: {select_string}")
        return select_string
    
    def _query_companies_from_id(self, client_config: Dict[str, Any], start_id: int, limit: int, exclude_ids: Optional[set] = None) -> List[Dict[str, Any]]:
        """æŒ‡å®šã—ãŸIDä»¥ä¸Šã®ä¼æ¥­ã‚’æŠ½å‡ºï¼ˆRPCé–¢æ•°ä½¿ç”¨ã€ç›´æ¥SQL WHEREå¥å®Ÿè¡Œï¼‰"""
        try:
            # é™¤å¤–IDã‚»ãƒƒãƒˆã‚’æº–å‚™
            if exclude_ids is None:
                exclude_ids = set()
            
            # RPCé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            companies = self._get_companies_using_rpc(client_config, start_id, limit, exclude_ids)
            
            # çµ±ä¸€ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ï¼ˆå¿µã®ãŸã‚ã€ä¸»ãªå‡¦ç†ã¯RPCå´ã§å®Œäº†ï¼‰
            companies = self._apply_unified_filters(companies, client_config)
            
            # å„ªå…ˆåº¦ã«åŸºã¥ãä¸¦ã³æ›¿ãˆã¨åˆ¶é™
            companies = self._get_companies_by_priority(companies, limit)
            
            logger.info(f"Retrieved {len(companies)} companies using RPC function with unified filters including prohibition_detected exclusion (ID >= {start_id})")
            
            return companies
            
        except Exception as e:
            logger.error(f"Error querying companies from ID {start_id} using RPC: {e}")
            raise ValueError(f"Failed to query companies: {e}") from e
    
    def _fetch_companies_bulk(self, client_config: Dict[str, Any], limit: int = 1000) -> List[Dict[str, Any]]:
        """FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : æœ€å¤§1000ä»¶ã®ä¼æ¥­ã‚’ä¸€æ‹¬å–å¾—ï¼ˆãƒ©ãƒ³ãƒ€ãƒ IDé–‹å§‹ç‚¹æ–¹å¼ï¼‰"""
        try:
            # ä¼æ¥­IDæŒ‡å®šãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
            if client_config.get('company_id') is not None:
                specific_company_id = client_config.get('company_id')
                logger.info(f"Specific company mode: fetching company ID {specific_company_id}")
                
                # æŒ‡å®šä¼æ¥­ã®ã¿ã‚’å–å¾—
                companies = self._query_companies_from_id(client_config, specific_company_id, 1)
                if companies:
                    # IDãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã®ã¿ã«çµã‚Šè¾¼ã¿
                    specific_companies = [c for c in companies if c['id'] == specific_company_id]
                    if specific_companies:
                        logger.info(f"Found specified company: {specific_companies[0].get('company_name', 'Unknown')}")
                        return specific_companies
                    else:
                        logger.warning(f"Company ID {specific_company_id} not found in results")
                        return []
                else:
                    logger.warning(f"No company found with ID {specific_company_id}")
                    return []
            
            # å¾“æ¥ã®ãƒ©ãƒ³ãƒ€ãƒ å–å¾—ãƒ¢ãƒ¼ãƒ‰
            import random
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªé–‹å§‹IDã‚’ç”Ÿæˆ (å‹•çš„æœ€å¤§IDå–å¾—)
            max_record_id = self._get_max_record_id()
            random_start_id = random.randint(1, max_record_id)
            
            logger.info(f"Fetching bulk companies (limit: {limit}) starting from random ID: {random_start_id}")
            
            # 1. random_idä»¥ä¸Šã®ä¼æ¥­ã‚’æŠ½å‡º
            companies = self._query_companies_from_id(client_config, random_start_id, limit)
            logger.info(f"Fetched {len(companies)} companies from ID >= {random_start_id}")
            
            # 2. ä¸è¶³æ™‚ã¯1ä»¥ä¸Šã§è£œå®Œï¼ˆåŠ¹ç‡çš„ãªé™¤å¤–IDå‡¦ç†ï¼‰
            if len(companies) < limit:
                additional_needed = limit - len(companies)
                logger.info(f"Need {additional_needed} more companies, fetching from ID >= 1")
                
                # æ—¢ã«å–å¾—ã—ãŸä¼æ¥­ã®IDã‚’é™¤å¤–ã‚»ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨
                existing_ids = {c['id'] for c in companies}
                
                # åŠ¹ç‡çš„ãªã‚¯ã‚¨ãƒªã§é‡è¤‡ã‚’äº‹å‰ã«é™¤å¤–ï¼ˆé™¤å¤–IDã‚’åˆ¶é™ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
                limited_existing_ids = existing_ids if len(existing_ids) <= 50 else set(list(existing_ids)[:50])
                additional_companies = self._query_companies_from_id(
                    client_config, 1, additional_needed * 2, exclude_ids=limited_existing_ids  # é™¤å¤–ã‚’è€ƒæ…®ã—ã¦å¤šã‚ã«å–å¾—
                )
                
                # å¿µã®ãŸã‚ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã§é™¤å¤–ã•ã‚Œã¦ã„ã‚‹ã¯ãšã ãŒå®‰å…¨ã®ãŸã‚ï¼‰
                filtered_additional = []
                for company in additional_companies:
                    if company['id'] not in existing_ids and len(companies) + len(filtered_additional) < limit:
                        filtered_additional.append(company)
                
                companies.extend(filtered_additional)
                
                logger.info(f"Added {len(filtered_additional)} companies from beginning, total: {len(companies)}")
            
            return companies
            
        except Exception as e:
            logger.error(f"Error fetching companies in bulk (all retries failed): {e}")
            return []
    
    def _save_companies_to_temp_file(self, companies: List[Dict[str, Any]]):
        """FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : ä¼æ¥­æƒ…å ±ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            # æ—¢å­˜ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.temp_companies_file and os.path.exists(self.temp_companies_file):
                os.remove(self.temp_companies_file)
            
            # æ–°ã—ã„ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
                json.dump(companies, f, ensure_ascii=False, indent=2)
                self.temp_companies_file = f.name
            
            logger.info(f"Saved {len(companies)} companies to temporary file: {self.temp_companies_file}")
            
        except Exception as e:
            logger.error(f"Error saving companies to temporary file: {e}")
            raise
    
    def _load_next_batch_from_temp_file(self, batch_size: int = 10) -> List[Dict[str, Any]]:
        """FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰10ä»¶ãšã¤èª­ã¿è¾¼ã¿"""
        try:
            # ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã‚ŠãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
            if len(self.companies_buffer) >= batch_size:
                batch = self.companies_buffer[:batch_size]
                self.companies_buffer = self.companies_buffer[batch_size:]
                return batch
            
            # ãƒãƒƒãƒ•ã‚¡ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è£œå……
            if self.temp_companies_file and os.path.exists(self.temp_companies_file):
                with open(self.temp_companies_file, 'r') as f:
                    all_companies = json.load(f)
                
                # å‡¦ç†æ¸ˆã¿ã®ä¼æ¥­ã‚’é™¤å¤–ã—ã¦ãƒãƒƒãƒ•ã‚¡ã«è£œå……
                remaining_companies = all_companies[self.processed_count:]
                self.companies_buffer.extend(remaining_companies)
                
                # ãƒãƒƒãƒã‚’ä½œæˆ
                if len(self.companies_buffer) >= batch_size:
                    batch = self.companies_buffer[:batch_size]
                    self.companies_buffer = self.companies_buffer[batch_size:]
                    return batch
                else:
                    # æ®‹ã‚Šå…¨éƒ¨ã‚’è¿”ã™
                    batch = self.companies_buffer
                    self.companies_buffer = []
                    return batch
            
            return []
            
        except Exception as e:
            logger.error(f"Error loading batch from temporary file: {e}")
            return []
    
    def get_target_companies_batch(self, client_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        FORM_SENDER.md 1.4.1ä»•æ§˜æº–æ‹ : å¤§é‡å–å¾—+ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†æ–¹å¼ã§10ä»¶ãšã¤å–å¾—
        
        å‡¦ç†ãƒ•ãƒ­ãƒ¼:
        1. åˆå›å¤§é‡å–å¾—: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹æ™‚ã«æœ€å¤§1000ä»¶ã®å‡¦ç†å¯¾è±¡ä¼æ¥­ã‚’å–å¾—
        2. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: å–å¾—ã—ãŸä¼æ¥­æƒ…å ±ã‚’JSONå½¢å¼ã§ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        3. é †æ¬¡å‡¦ç†: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰10ä»¶ãšã¤èª­ã¿è¾¼ã‚“ã§å‡¦ç†å®Ÿè¡Œ
        4. æ®‹ä»¶ç®¡ç†: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®æ®‹ä»¶æ•°ãŒ0ä»¶ã«ãªã£ãŸã‚‰å†ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        5. å†å–å¾—: æ–°ã—ã„å‡¦ç†å¯¾è±¡ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ å–å¾—ã—ã¦ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        """
        try:
            # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰10ä»¶ãšã¤èª­ã¿è¾¼ã¿
            batch = self._load_next_batch_from_temp_file(10)
            
            # Step 4: æ®‹ä»¶ç®¡ç† - ãƒãƒƒãƒãŒç©ºã®å ´åˆã¯å†å–å¾—ã‚’è©¦è¡Œ
            if not batch:
                logger.info("No companies in buffer, attempting bulk fetch...")
                
                # Step 1 & 5: åˆå›å¤§é‡å–å¾— / å†å–å¾—
                companies = self._fetch_companies_bulk(client_config, 1000)
                
                if companies:
                    # Step 2: ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                    self._save_companies_to_temp_file(companies)
                    
                    # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰10ä»¶ãšã¤èª­ã¿è¾¼ã¿ï¼ˆå†è©¦è¡Œï¼‰
                    batch = self._load_next_batch_from_temp_file(10)
                    
                    logger.info(f"Bulk fetch successful, loaded batch of {len(batch)} companies")
                else:
                    logger.info("No more companies available for processing")
                    return []
            
            # å–å¾—çµæœã®è©³ç´°ãƒ­ã‚°ï¼ˆä¼šç¤¾åã¯æ©Ÿå¯†æƒ…å ±ã®ãŸã‚ãƒã‚¹ã‚¯ï¼‰
            if batch:
                logger.info(f"Loaded batch: {len(batch)} companies ready for processing")
                for i, company in enumerate(batch[:3]):  # æœ€åˆã®3ä»¶ã®ã¿ãƒ­ã‚°å‡ºåŠ›
                    logger.debug(
                        f"Company {i+1}: id={company['id']}, has_form_url={bool(company.get('form_url'))}, mapping='rule_based'"
                    )
            
            return batch
            
        except Exception as e:
            logger.error(f"Error getting target companies batch: {e}")
            return []
    
    def _filter_by_submission_history(self, companies: List[Dict[str, Any]], allow_failed: bool = False) -> List[Dict[str, Any]]:
        """é€ä¿¡å±¥æ­´ã«ã‚ˆã‚‹ä¼æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå„ªå…ˆåº¦ä»˜ãï¼‰"""
        try:
            if not companies:
                return []
                
            record_ids = [company['id'] for company in companies]
            
            # å…¨é€ä¿¡è¨˜éŒ²ã‚’å–å¾—ï¼ˆæˆåŠŸãƒ»å¤±æ•—ä¸¡æ–¹ï¼‰
            def get_submission_history():
                return self.supabase_client.table('submissions') \
                    .select('company_id, success') \
                    .eq('targeting_id', self.targeting_id) \
                    .in_('company_id', record_ids) \
                    .execute()
            
            response = self.db_manager.execute_with_retry_sync(
                f"get_submission_history_targeting_{self.targeting_id}",
                get_submission_history
            )
            
            submission_data = response.data if response.data else []
            
            # ä¼æ¥­IDã”ã¨ã®é€ä¿¡çŠ¶æ³ã‚’åˆ†æ
            company_status = {}
            for record in submission_data:
                record_id = record['company_id']  # DBã‚«ãƒ©ãƒ åã¯company_idã®ã¾ã¾
                success = record['success']
                
                if record_id not in company_status:
                    company_status[record_id] = {'success': False, 'failed': False}
                
                if success is True:
                    company_status[record_id]['success'] = True
                elif success is False:
                    company_status[record_id]['failed'] = True
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
            filtered_companies = []
            for company in companies:
                record_id = company['id']
                
                if record_id not in company_status:
                    # è¨˜éŒ²ãªã—ä¼æ¥­ - å¸¸ã«å¯¾è±¡
                    filtered_companies.append(company)
                elif company_status[record_id]['success']:
                    # æˆåŠŸè¨˜éŒ²ã‚ã‚Š - å¸¸ã«é™¤å¤–
                    continue
                elif company_status[record_id]['failed'] and allow_failed:
                    # å¤±æ•—è¨˜éŒ²ã®ã¿ - allow_failedãŒTrueã®å ´åˆã®ã¿å¯¾è±¡
                    filtered_companies.append(company)
                # else: å¤±æ•—è¨˜éŒ²ã®ã¿ã§allow_failed=False - é™¤å¤–
            
            no_record_count = len([c for c in companies if c['id'] not in company_status])
            success_excluded = len([c for c in companies if c['id'] in company_status and company_status[c['id']]['success']])
            failed_excluded = len([c for c in companies if c['id'] in company_status and company_status[c['id']]['failed'] and not company_status[c['id']]['success'] and not allow_failed])
            
            logger.info(f"Company filtering results: no_record={no_record_count}, "
                       f"success_excluded={success_excluded}, failed_excluded={failed_excluded}, "
                       f"allow_failed={allow_failed}, final_count={len(filtered_companies)}")
            
            return filtered_companies
            
        except Exception as e:
            logger.error(f"Error filtering by submission history: {e}")
            return companies  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒªã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
    
    def _get_companies_by_priority(self, all_companies: List[Dict[str, Any]], target_limit: int) -> List[Dict[str, Any]]:
        """å„ªå…ˆåº¦ä»˜ãä¼æ¥­å–å¾—ï¼ˆ2æ®µéšå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        try:
            if not all_companies:
                return []
            
            logger.info(f"Starting priority-based company selection from {len(all_companies)} candidates")
            
            # ç¬¬1æ®µéš: è¨˜éŒ²ãªã—ä¼æ¥­ã‚’å„ªå…ˆå–å¾—
            no_record_companies = self._filter_by_submission_history(all_companies, allow_failed=False)
            logger.info(f"Phase 1 - No record companies: {len(no_record_companies)}")
            
            if len(no_record_companies) >= target_limit:
                # è¨˜éŒ²ãªã—ä¼æ¥­ã ã‘ã§ååˆ†
                result = no_record_companies[:target_limit]
                logger.info(f"Sufficient companies from no-record group: {len(result)}")
                return result
            
            # ç¬¬2æ®µéš: è¨˜éŒ²ãªã—ä¼æ¥­ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã€æˆåŠŸè¨˜éŒ²ã®ãªã„ä¼æ¥­ã‚’è¿½åŠ 
            logger.info(f"Phase 1 insufficient ({len(no_record_companies)}/{target_limit}), proceeding to phase 2")
            
            # æˆåŠŸè¨˜éŒ²ã®ãªã„ä¼æ¥­ï¼ˆè¨˜éŒ²ãªã— + å¤±æ•—ã®ã¿ï¼‰ã‚’å–å¾—
            no_success_companies = self._filter_by_submission_history(all_companies, allow_failed=True)
            logger.info(f"Phase 2 - No success record companies: {len(no_success_companies)}")
            
            # target_limitã¾ã§å–å¾—
            result = no_success_companies[:target_limit]
            logger.info(f"Final selection: {len(result)} companies (no_record: {len(no_record_companies)}, "
                       f"additional_no_success: {len(result) - len(no_record_companies)})")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in priority-based company selection: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾“æ¥ã®æ–¹æ³•ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._filter_by_submission_history(all_companies, allow_failed=False)
    
    def _filter_already_sent_companies(self, companies: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """é€ä¿¡æ¸ˆã¿ä¼æ¥­ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å¾Œæ–¹äº’æ›ï¼‰"""
        # æ–°ã—ã„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨ï¼ˆæˆåŠŸè¨˜éŒ²ã®ãªã„ä¼æ¥­ã®ã¿ï¼‰
        return self._filter_by_submission_history(companies, allow_failed=False)
    
    def cleanup_temp_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.temp_companies_file and os.path.exists(self.temp_companies_file):
                os.remove(self.temp_companies_file)
                logger.info(f"Cleaned up temporary file: {self.temp_companies_file}")
                self.temp_companies_file = None
        except Exception as e:
            logger.error(f"Error cleaning up temporary file: {e}")
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """å‡¦ç†ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        elapsed_time = time.time() - self.start_time
        return {
            'targeting_id': self.targeting_id,
            'processed_count': self.processed_count,
            'success_count': self.success_count,
            'failed_count': self.failed_count,
            'elapsed_time': elapsed_time,
            'processing_mode': 'continuous_loop'
        }

#!/usr/bin/env python3
"""
å–¶æ¥­ç¦æ­¢æ–‡è¨€æ¤œå‡ºãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«ï¼ˆå˜ç™ºå®Ÿè¡Œï¼‰

- Supabase ã‹ã‚‰å‡¦ç†å¯¾è±¡ã‚’1ä»¶å–å¾—ï¼ˆ--company-id æŒ‡å®šå¯ï¼‰
- Playwright ã§å¯¾è±¡URLã¸ã‚¢ã‚¯ã‚»ã‚¹ã—ã€CookieåŒæ„å‡¦ç†ã¨å‹•çš„å¾…æ©Ÿï¼ˆHubSpotç­‰ï¼‰ã‚’å®Ÿæ–½
- å®Ÿè¡Œç³»ã¨åŒç­‰ã®æ¤œå‡ºå™¨ï¼ˆSalesProhibitionDetector + ProhibitionDetectorï¼‰ã§å–¶æ¥­ç¦æ­¢æ–‡è¨€ã‚’æ¤œå‡º
- å®Ÿè¡Œç³»ã¨åŒã˜è©•ä¾¡åŸºæº–ï¼ˆconfig/worker_config.json ã® early_abort ã—ãã„å€¤ï¼‰ã§åˆ¤å®šã‚’å‡ºåŠ›
- ãƒãƒƒãƒ”ãƒ³ã‚°ã‚„å®Ÿé€ä¿¡ã¯ä¸€åˆ‡è¡Œã‚ãªã„
- ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ï¼ˆå¿…è¦ã«å¿œã˜ã¦iframeçµåˆï¼‰ã¨æ¤œå‡ºçµæœJSONã‚’ test_results/ é…ä¸‹ã«ä¿å­˜
"""

import argparse
import asyncio
import json
import logging
import os
import random
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# Optional BeautifulSoup (required-fieldsæŠ½å‡ºã»ã©ã¯ä½¿ã‚ãªã„ãŒã€iframeçµåˆã®æ•´å½¢ã«åˆ©ç”¨)
try:
    from bs4 import BeautifulSoup  # type: ignore

    HAS_BEAUTIFULSOUP = True
except Exception:
    HAS_BEAUTIFULSOUP = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’ import path ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root))

from playwright.async_api import async_playwright, Browser, Page
from supabase import create_client

# å®Ÿè¡Œç³»ã¨åŒã˜æ¤œå‡ºå™¨
from form_sender.analyzer.sales_prohibition_detector import SalesProhibitionDetector
from form_sender.utils.cookie_handler import CookieConsentHandler
from config.manager import get_worker_config
from dataclasses import is_dataclass, asdict


# --- Logging (quiet ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ + ã‚µãƒ‹ã‚¿ã‚¤ã‚º) ---
logger = logging.getLogger(__name__)


class SanitizingFormatter(logging.Formatter):
    """LogSanitizer ã‚’ç”¨ã„ã¦å‡ºåŠ›ç›´å‰ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿"""

    def __init__(self, fmt: str = "%(asctime)s - %(levelname)s - %(message)s", datefmt: Optional[str] = None):
        super().__init__(fmt=fmt, datefmt=datefmt)
        try:
            from form_sender.security.log_sanitizer import LogSanitizer

            self._sanitizer = LogSanitizer()
        except Exception:
            self._sanitizer = None

    def format(self, record: logging.LogRecord) -> str:  # type: ignore[override]
        rendered = super().format(record)
        if self._sanitizer:
            try:
                return self._sanitizer.sanitize_string(rendered)
            except Exception:
                return rendered
        return rendered


class SummaryOnlyFilter(logging.Filter):
    """quietãƒ¢ãƒ¼ãƒ‰ã§å‡ºåŠ›ã‚’ã‚µãƒãƒªä¸­å¿ƒã«åˆ¶å¾¡ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã€‚"""

    def __init__(self, quiet: bool = True):
        super().__init__()
        self.quiet = quiet

    def filter(self, record: logging.LogRecord) -> bool:  # type: ignore[override]
        if not self.quiet:
            return True
        if record.levelno >= logging.ERROR:
            return True
        if bool(getattr(record, "summary", False)):
            return True
        # INFO/DEBUG ã¯quietã§ã¯è¡¨ç¤ºã—ãªã„
        return False


def configure_logging(verbose: bool = False, debug: bool = False) -> None:
    level = logging.DEBUG if debug else (logging.INFO if verbose else logging.INFO)
    quiet = not (verbose or debug)

    root = logging.getLogger()
    for h in list(root.handlers):
        root.removeHandler(h)

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(SanitizingFormatter("%(asctime)s - %(levelname)s - %(message)s"))
    if quiet:
        handler.addFilter(SummaryOnlyFilter(quiet=True))

    root.addHandler(handler)
    root.setLevel(level)


class ProhibitionDetectionTester:
    """å–¶æ¥­ç¦æ­¢æ–‡è¨€æ¤œå‡ºã®å˜ç™ºãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context = None
        self.page: Optional[Page] = None
        self.supabase_client = None
        self._initialized = False

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = project_root / "test_results" / f"prohibition_{timestamp}"
        out_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir = str(out_dir)

    async def __aenter__(self):
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        await self.cleanup()
        return False

    async def initialize(self):
        if self._initialized:
            return
        await self._initialize_supabase()
        await self._initialize_browser()
        self._initialized = True
        logger.info("âœ… ProhibitionDetectionTester initialized")

    async def cleanup(self):
        try:
            if self.page and not self.page.is_closed():
                await self.page.close()
        except Exception:
            pass
        try:
            if self.context:
                await self.context.close()
        except Exception:
            pass
        try:
            if self.browser:
                await self.browser.close()
        except Exception:
            pass
        try:
            if self.playwright:
                await self.playwright.stop()
        except Exception:
            pass

    async def _initialize_supabase(self):
        try:
            from dotenv import load_dotenv

            load_dotenv(override=True)
            url = os.getenv("SUPABASE_URL")
            key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
            if not url or not key:
                raise RuntimeError("Supabase credentials not found in .env")
            self.supabase_client = create_client(url, key)
        except Exception as e:
            logger.error(f"Supabase initialization failed: {e}")
            raise

    async def _initialize_browser(self):
        try:
            self.playwright = await async_playwright().start()
            headless = True  # å¸¸ã«ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼ˆé‹ç”¨æ–¹é‡ï¼‰

            engine = os.getenv("PLAYWRIGHT_ENGINE", "chromium").lower()
            engine_map = {
                "chromium": self.playwright.chromium,
                "webkit": self.playwright.webkit,
                "firefox": self.playwright.firefox,
            }
            launcher = engine_map.get(engine, self.playwright.chromium)
            if engine not in engine_map:
                logger.warning(f"Unknown PLAYWRIGHT_ENGINE='{engine}', falling back to chromium")

            extra_args: List[str] = []
            if engine == "chromium":
                is_linux = sys.platform.startswith("linux")
                extra_args = ["--disable-dev-shm-usage", "--disable-blink-features=AutomationControlled"]
                if is_linux:
                    extra_args += ["--no-sandbox", "--disable-setuid-sandbox"]
                if headless:
                    extra_args += ["--disable-gpu"]

            launch_kwargs = dict(headless=headless, args=extra_args)
            if engine == "chromium":
                try:
                    self.browser = await launcher.launch(channel="chrome", **launch_kwargs)
                except Exception:
                    self.browser = await launcher.launch(**launch_kwargs)
            else:
                self.browser = await launcher.launch(**launch_kwargs)

            self.context = await self.browser.new_context(
                ignore_https_errors=True,
                java_script_enabled=True,
                bypass_csp=True,
                viewport={"width": 1366, "height": 900},
            )

            await self.context.add_init_script(
                """
                (() => { try {
                  const noop = () => false;
                  Object.defineProperty(window, 'close', { value: noop, configurable: true });
                  const _open = window.open;
                  Object.defineProperty(window, 'open', { value: (url, target, features) => {
                    try { window.location.href = url; } catch {}
                    return window;
                  }, configurable: true });
                } catch {} })();
                """
            )

            # è»½é‡ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼ˆè¿½è·¡ç³»ã®ã¿ï¼‰
            async def handle_route(route):
                r = route.request
                rtype = r.resource_type
                url = r.url.lower()
                if rtype in ["image", "media", "font", "manifest", "other"]:
                    await route.abort()
                    return
                if rtype == "stylesheet":
                    await route.abort()
                    return
                if rtype == "script":
                    trackers = [
                        "googletagmanager.com",
                        "google-analytics.com",
                        "doubleclick.net",
                        "googlesyndication.com",
                        "facebook.net",
                        "connect.facebook.net",
                        "hotjar.com",
                        "mixpanel.com",
                        "amplitude.com",
                    ]
                    if any(k in url for k in trackers):
                        await route.abort()
                        return
                await route.continue_()

            await self.context.route("**/*", handle_route)

            self.context.set_default_navigation_timeout(30000)
            self.page = await self.context.new_page()
            self.page.on("close", lambda: logger.debug("Active page closed (event)"))
        except Exception as e:
            logger.error(f"Browser initialization failed: {e}")
            raise

    async def _recreate_page(self):
        try:
            if self.page and not self.page.is_closed():
                await self.page.close()
        except Exception:
            pass
        try:
            if self.context is None:
                return
            await self.context.add_init_script(
                """
                (() => { try {
                  const noop = () => false;
                  Object.defineProperty(window, 'close', { value: noop, configurable: true });
                  const _open = window.open;
                  Object.defineProperty(window, 'open', { value: (url, target, features) => {
                    try { window.location.href = url; } catch {}
                    return window;
                  }, configurable: true });
                } catch {} })();
                """
            )
            await self.context.set_extra_http_headers(
                {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}
            )
            self.context.set_default_navigation_timeout(30000)

            async def handle_route(route):
                r = route.request
                rtype = r.resource_type
                url = r.url.lower()
                if rtype in ["image", "media", "font", "manifest", "other"]:
                    await route.abort()
                    return
                if rtype == "stylesheet":
                    await route.abort()
                    return
                if rtype == "script":
                    trackers = [
                        "googletagmanager.com",
                        "google-analytics.com",
                        "doubleclick.net",
                        "googlesyndication.com",
                        "facebook.net",
                        "connect.facebook.net",
                        "hotjar.com",
                        "mixpanel.com",
                        "amplitude.com",
                    ]
                    if any(k in url for k in trackers):
                        await route.abort()
                        return
                await route.continue_()

            await self.context.route("**/*", handle_route)
            self.page = await self.context.new_page()
            self.page.on("close", lambda: logger.debug("Active page closed (event)"))
        except Exception as e:
            logger.debug(f"recreate page failed: {e}")

    async def fetch_test_form_url(self, company_id: Optional[int] = None) -> Optional[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ä¼æ¥­1ä»¶ã‚’å–å¾—ï¼ˆIDæŒ‡å®š or ã—ãã„å€¤ãƒ©ãƒ³ãƒ€ãƒ æ¢ç´¢ï¼‰"""
        try:
            cfg_path = project_root / "config" / "test_field_mapping.json"
            defaults = {"min_company_id": 1, "max_company_id": 536156, "max_retries": 10, "form_url_scheme": "http%"}
            try:
                data = json.loads(cfg_path.read_text(encoding="utf-8"))
                cfg = {**defaults, **{k: v for k, v in data.items() if k in defaults}}
            except FileNotFoundError:
                logger.info("Config not found: config/test_field_mapping.json (using defaults)")
                cfg = defaults
            except Exception as e:
                logger.warning(f"Failed to load config/test_field_mapping.json: {e} (using defaults)")
                cfg = defaults

            if company_id:
                resp = (
                    self.supabase_client.table("companies")
                    .select("id, company_name, form_url, instruction_json, company_url")
                    .eq("id", company_id)
                    .neq("form_url", None)
                    .ilike("form_url", "http%")
                    .limit(1)
                    .execute()
                )
                if not resp.data:
                    logger.error(f"Company with ID {company_id} not found or has no http form_url")
                    return None
                company = resp.data[0]
                logger.info("âœ… Specific company selected", extra={"summary": True})
            else:
                min_id = int(cfg.get("min_company_id", 1))
                max_id = int(cfg.get("max_company_id", 536156))
                max_retries = int(cfg.get("max_retries", 10))
                scheme = str(cfg.get("form_url_scheme", "http%"))
                if min_id < 1:
                    min_id = 1
                if max_id < min_id:
                    max_id = min_id
                company = None
                for attempt in range(1, max_retries + 1):
                    threshold = random.randint(min_id, max_id)
                    logger.info(f"Attempt {attempt}/{max_retries} with threshold >= {threshold}")
                    resp = (
                        self.supabase_client.table("companies")
                        .select("id, company_name, form_url, instruction_json, company_url")
                        .neq("form_url", None)
                        .ilike("form_url", scheme)
                        .gte("id", threshold)
                        .order("id", desc=False)
                        .limit(1)
                        .execute()
                    )
                    if resp.data:
                        company = resp.data[0]
                        break
                if not company:
                    logger.error("Failed to find any company with http form_url after retries")
                    return None
                logger.info("âœ… Test company selected via threshold search", extra={"summary": True})

            logger.info(f"ğŸ¯ Target company_id: {company['id']}", extra={"summary": True})
            logger.info("   Company: ***COMPANY_REDACTED***")
            logger.info("   Form URL: ***URL_REDACTED***")
            return company
        except Exception as e:
            logger.error(f"Failed to fetch test form URL: {e}")
            return None

    async def _goto_with_popup_recovery(self, url: str) -> None:
        popup_captured: List[Page] = []

        def _on_popup(p):
            try:
                popup_captured.append(p)
                logger.debug("Popup captured during navigation")
            except Exception:
                pass

        assert self.page is not None
        self.page.once("popup", _on_popup)

        try:
            await self.page.goto(url, wait_until="domcontentloaded", timeout=25000)
        except Exception as e:
            if "has been closed" in str(e) and popup_captured:
                candidate = popup_captured[-1]
                try:
                    is_closed = bool(candidate.is_closed())
                except Exception:
                    is_closed = False
                if not is_closed:
                    self.page = candidate
                    logger.info("Detected self-close -> switched to popup page")
                else:
                    logger.info("Captured popup already closed. Recreating page and retrying...")
                    await self._recreate_page()
                    assert self.page is not None
                    await self.page.goto(url, wait_until="domcontentloaded", timeout=25000)
            elif "has been closed" in str(e):
                logger.info("Detected unexpected page close. Recreating page and retrying once...")
                await self._recreate_page()
                assert self.page is not None
                await self.page.goto(url, wait_until="domcontentloaded", timeout=25000)
            else:
                raise

    async def _stabilize_after_navigation(self) -> None:
        assert self.page is not None
        await asyncio.sleep(0.5)
        await CookieConsentHandler.handle(self.page)

    async def _detect_initial_form_and_hubspot(self) -> Tuple[int, bool]:
        assert self.page is not None
        form_count = await self.page.evaluate("document.querySelectorAll('form').length")
        has_hs = await self.page.evaluate(
            """
            () => {
              const scripts = Array.from(document.querySelectorAll('script'));
              return scripts.some(s => s.src && (s.src.includes('hsforms.net') || s.src.includes('hubspot')));
            }
            """
        )
        logger.info(f"ğŸ“‹ Initial forms={form_count}, hubspot_script={bool(has_hs)}")
        return int(form_count), bool(has_hs)

    async def _wait_for_dynamic_content(self, max_wait: int = 15) -> bool:
        assert self.page is not None
        logger.info("ğŸ”„ Waiting for dynamic content...")
        try:
            await self.page.wait_for_load_state("networkidle", timeout=15000)
        except Exception:
            pass

        # è»½é‡JSç¢ºèªï¼ˆãƒ•ã‚©ãƒ¼ãƒ  or å…¥åŠ›å¢—åŠ ï¼‰
        try:
            final_check = await self.page.evaluate(
                """
                () => {
                  const forms = document.querySelectorAll('form').length;
                  const inputs = document.querySelectorAll('input').length;
                  const textareas = document.querySelectorAll('textarea').length;
                  const selects = document.querySelectorAll('select').length;
                  return {forms, inputs, textareas, selects};
                }
                """
            )
            total = final_check["forms"] + final_check["inputs"] + final_check["textareas"] + final_check["selects"]
            if total > 0:
                logger.info(f"âœ… Elements present after wait: forms={final_check['forms']}, inputs={final_check['inputs']}")
                return True
        except Exception:
            pass

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(2)
            await self.page.evaluate("window.scrollTo(0, 0)")
            await asyncio.sleep(1)
            forms = await self.page.evaluate("document.querySelectorAll('form').length")
            if int(forms or 0) > 0:
                return True
        except Exception:
            pass
        return False

    async def _analyze_iframes(self) -> Tuple[str, Optional[Any]]:
        """iframeã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ ãŒã‚ã‚Šãã†ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºï¼ˆä¿å­˜ç”¨HTMLã‚‚åé›†ï¼‰"""
        assert self.page is not None
        iframe_contents: List[str] = []
        target_frame = None
        try:
            for frame in self.page.frames:
                if frame == self.page.main_frame:
                    continue
                try:
                    content = await frame.content()
                    forms = await frame.query_selector_all("form")
                    has_forms = len(forms) > 0
                    if HAS_BEAUTIFULSOUP:
                        soup = BeautifulSoup(content, "html.parser")
                        only_forms = soup.find_all("form")
                        if only_forms:
                            iframe_contents.append("\n".join(str(f) for f in only_forms))
                    else:
                        if "<form" in content.lower():
                            iframe_contents.append(content)
                    if has_forms and not target_frame:
                        target_frame = frame
                except Exception:
                    continue
        except Exception:
            pass
        return ("\n\n".join(iframe_contents), target_frame)

    async def _extract_page_source_with_iframes(self, form_count: int) -> Tuple[str, Optional[Any]]:
        """ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‚’ä¿å­˜ç”¨ã«æŠ½å‡ºã€‚å¿…è¦ãªã‚‰iframeã‚‚çµåˆã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ã‚‚è¿”ã™ã€‚"""
        assert self.page is not None
        page_source = await self.page.content()

        need_iframe = False
        if form_count == 0:
            need_iframe = True
        else:
            try:
                inputs = await self.page.evaluate("document.querySelectorAll('input, textarea, select').length")
                if int(inputs or 0) == 0:
                    need_iframe = True
            except Exception:
                pass

        target_frame = None
        if need_iframe:
            iframe_content, target_frame = await self._analyze_iframes()
            if iframe_content:
                page_source += "\n\n" + iframe_content

        return page_source, target_frame

    async def _save_page_source(self, content: str) -> str:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        path = os.path.join(self.temp_dir, f"page_source_{ts}.html")
        with open(path, "w", encoding="utf-8") as f:
            f.write(content)
        logger.info(f"ğŸ“„ Page source saved: {path}", extra={"summary": True})
        return path

    def _evaluate_prohibition_detection(self, sp: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:
        """å®Ÿè¡Œç³»(Worker)ã¨åŒç­‰ã®åŸºæº–ã§æ—©æœŸä¸­æ–­è¦å¦ã‚’è©•ä¾¡"""
        if not isinstance(sp, dict):
            return False, {"level": "none", "confidence_level": "none", "confidence_score": 0.0, "matches_count": 0}

        matches = sp.get("matches") or []
        level = (sp.get("prohibition_level") or sp.get("detection_method") or "detected")
        level_l = str(level).lower()
        conf_level = str(sp.get("confidence_level") or "").lower()
        try:
            conf_score = float(sp.get("confidence_score") or 0.0)
        except Exception:
            conf_score = 0.0
        if conf_score < 0:
            conf_score = 0.0
        if conf_score > 100:
            conf_score = 100.0
        try:
            matches_count = int(sp.get("summary", {}).get("total_matches"))
        except Exception:
            matches_count = len(matches)

        # ã—ãã„å€¤ã¯ config/worker_config.json ã¨ä¸€è‡´ã•ã›ã‚‹
        try:
            det = (get_worker_config() or {}).get("detectors", {}).get("prohibition", {})
            lvl_min = str(det.get("early_abort", {}).get("min_level", "moderate")).lower()
            conf_lvl_min = str(det.get("early_abort", {}).get("min_confidence_level", "high")).lower()
            score_min = float(det.get("early_abort", {}).get("min_score", 80))
            matches_min = int(det.get("early_abort", {}).get("min_matches", 2))
        except Exception:
            lvl_min, conf_lvl_min, score_min, matches_min = "moderate", "high", 80.0, 2

        order = {"weak": 0, "mild": 1, "moderate": 2, "strict": 3}
        lvl_min_idx = order.get(lvl_min, 2)
        level_idx = order.get(level_l, order.get("moderate", 2))

        should_abort = False
        if level_idx >= lvl_min_idx:
            should_abort = True
        elif conf_level == conf_lvl_min or conf_score >= score_min:
            should_abort = True
        elif matches_count >= matches_min:
            should_abort = True

        summary = {
            "level": level,
            "confidence_level": conf_level or None,
            "confidence_score": conf_score if conf_score > 0 else None,
            "matches_count": matches_count,
        }
        return should_abort, summary

    async def run_single_test(self, company_id: Optional[int] = None) -> bool:
        try:
            company = await self.fetch_test_form_url(company_id)
            if not company:
                return False

            assert self.page is not None
            url = company["form_url"]
            logger.info("Starting prohibition detection...", extra={"summary": True})
            logger.info("Target URL: ***URL_REDACTED***")

            await self._goto_with_popup_recovery(url)
            await self._stabilize_after_navigation()
            form_count, has_hs = await self._detect_initial_form_and_hubspot()
            if form_count == 0 or has_hs:
                await self._wait_for_dynamic_content()

            # ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ï¼ˆ+å¿…è¦ã«å¿œã˜ã¦iframeï¼‰ä¿å­˜ + ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ãƒ¬ãƒ¼ãƒ æ±ºå®š
            page_source, target_frame = await self._extract_page_source_with_iframes(form_count)
            source_file = await self._save_page_source(page_source)

            # å®Ÿè¡Œç³»ã¨åŒã˜æ¤œå‡ºå™¨ã‚’ä½¿ã†ï¼ˆtarget_frameãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’å„ªå…ˆï¼‰
            detector_ctx = target_frame if target_frame else self.page
            sp = await SalesProhibitionDetector(detector_ctx).detect_prohibition_text()

            should_abort, summary = self._evaluate_prohibition_detection(sp or {})

            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            out_path = os.path.join(self.temp_dir, f"prohibition_result_{ts}.json")
            # dataclass(ProhibitionMatch) ã‚’å«ã‚€å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚JSONåŒ–
            serializable_sp = self._make_json_serializable(sp)
            payload = {
                "company_id": company["id"],
                "form_url": url,
                "timestamp": ts,
                "sales_prohibition": serializable_sp,
                "evaluation": {"should_abort": should_abort, **summary},
                "source_file": source_file,
            }
            # URLç­‰ã¯ãƒ­ã‚°ã§ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã•ã‚Œã‚‹ãŒã€ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å®Ÿå€¤ã‚’ä¿æŒ
            with open(out_path, "w", encoding="utf-8") as f:
                json.dump(payload, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ Detection result saved: {out_path}", extra={"summary": True})

            # ä¾é ¼: å–¶æ¥­ç¦æ­¢åˆ¤å®šï¼ˆtrue/falseï¼‰ã‚’ãƒ­ã‚°ã«æ˜ç¤º
            logger.info(
                f"å–¶æ¥­ç¦æ­¢åˆ¤å®š(should_abort): {'true' if should_abort else 'false'}",
                extra={"summary": True},
            )

            if should_abort:
                logger.warning(
                    f"åˆ¤å®š: å–¶æ¥­ç¦æ­¢ï¼ˆæ—©æœŸä¸­æ–­åŸºæº–ã«åˆè‡´ï¼‰ level={summary.get('level')}, matches={summary.get('matches_count')}, conf={summary.get('confidence_level')}/{summary.get('confidence_score')}"
                )
            else:
                logger.info(
                    f"åˆ¤å®š: å–¶æ¥­ç¦æ­¢ãªã—ï¼ˆæ—©æœŸä¸­æ–­åŸºæº–æœªæº€ï¼‰ level={summary.get('level')}, matches={summary.get('matches_count')}, conf={summary.get('confidence_level')}/{summary.get('confidence_score')}"
                )
            return True
        except Exception as e:
            logger.error(f"Detection test failed: {e}")
            return False

    def _make_json_serializable(self, obj: Any) -> Any:
        """æ¤œå‡ºçµæœã‚’JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢ã¸å†å¸°çš„ã«å¤‰æ›"""
        try:
            if obj is None or isinstance(obj, (str, int, float, bool)):
                return obj
            if isinstance(obj, dict):
                return {str(k): self._make_json_serializable(v) for k, v in obj.items()}
            if isinstance(obj, (list, tuple, set)):
                return [self._make_json_serializable(v) for v in obj]
            if is_dataclass(obj):
                return self._make_json_serializable(asdict(obj))
            # æœ€å¾Œã®æ‰‹æ®µ: æ–‡å­—åˆ—åŒ–
            return str(obj)
        except Exception:
            try:
                return str(obj)
            except Exception:
                return None


# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰: ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯
try:
    DEFAULT_TEST_TIMEOUT_SECONDS = int(os.getenv("PROHIBITION_TEST_TIMEOUT_SECONDS", "60"))
except Exception:
    DEFAULT_TEST_TIMEOUT_SECONDS = 60


async def main():
    parser = argparse.ArgumentParser(
        description="Sales Prohibition Detection Test (single-run)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python tests/test_prohibition_detector.py                    # Single random test
  python tests/test_prohibition_detector.py --company-id 12345 # Test specific company
""",
    )
    parser.add_argument("--company-id", type=int, help="Specific company ID to test")
    parser.add_argument("--verbose", action="store_true", help="Show normal logs (summary filter off)")
    parser.add_argument("--debug", action="store_true", help="Show debug logs")
    args = parser.parse_args()

    configure_logging(verbose=args.verbose, debug=args.debug)

    try:
        async with ProhibitionDetectionTester() as tester:
            try:
                ok = await asyncio.wait_for(tester.run_single_test(args.company_id), timeout=DEFAULT_TEST_TIMEOUT_SECONDS)
            except asyncio.TimeoutError:
                logger.error(f"â±ï¸ Test timed out after {DEFAULT_TEST_TIMEOUT_SECONDS} seconds")
                ok = False
            if ok:
                logger.info("ğŸ¯ Prohibition detection test completed successfully!", extra={"summary": True})
            else:
                logger.error("âŒ Prohibition detection test failed")
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}")


if __name__ == "__main__":
    asyncio.run(main())

#!/usr/bin/env python3
"""
ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ç²¾åº¦æ¤œè¨¼ãƒ»æ”¹å–„å°‚ç”¨ãƒ„ãƒ¼ãƒ«

å®Ÿéš›ã®form_urlã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç²¾åº¦ã‚’æ¤œè¨¼ã—ã€
æ®µéšçš„ãªæ”¹å–„ã‚’è¡Œã†ãŸã‚ã®åå¾©ãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«
"""

import argparse
import asyncio
import json
import logging
import os
import random
import sys
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

try:
    from bs4 import BeautifulSoup

    HAS_BEAUTIFULSOUP = True
except ImportError:
    HAS_BEAUTIFULSOUP = False
    print("âš ï¸ BeautifulSoup4 not installed. Install with: pip install beautifulsoup4")
    print("   Form content extraction will use basic fallback method.")

# ç’°å¢ƒè¨­å®š
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))
sys.path.insert(0, str(project_root))

from playwright.async_api import async_playwright, Browser, Page
from supabase import create_client

# ãƒ•ã‚©ãƒ¼ãƒ è§£æé–¢é€£
from form_sender.analyzer.rule_based_analyzer import RuleBasedAnalyzer
from form_sender.utils.cookie_handler import CookieConsentHandler
from tests.data.test_client_data import (
    CLIENT_DATA,
    TARGETING_DATA,
    create_test_client_config,
)

# ãƒ­ã‚°è¨­å®šï¼ˆquietãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ + ã‚µãƒ‹ã‚¿ã‚¤ã‚º + ã‚µãƒãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼‰
logger = logging.getLogger(__name__)


class SanitizingFormatter(logging.Formatter):
    """LogSanitizer ã‚’ç”¨ã„ã¦å‡ºåŠ›ç›´å‰ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿"""

    def __init__(
        self,
        fmt: str = "%(asctime)s - %(levelname)s - %(message)s",
        datefmt: Optional[str] = None,
    ):
        super().__init__(fmt=fmt, datefmt=datefmt)
        try:
            from form_sender.security.log_sanitizer import LogSanitizer

            self._sanitizer = LogSanitizer()
        except Exception:
            self._sanitizer = None

    def format(self, record: logging.LogRecord) -> str:
        rendered = super().format(record)
        if self._sanitizer:
            try:
                return self._sanitizer.sanitize_string(rendered)
            except Exception:
                return rendered
        return rendered


class SummaryOnlyFilter(logging.Filter):
    """quietãƒ¢ãƒ¼ãƒ‰ã§å‡ºåŠ›ã‚’ã‚µãƒãƒªä¸­å¿ƒã«åˆ¶å¾¡ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã€‚

    ä»•æ§˜ï¼ˆquiet=True ã®ã¨ãï¼‰:
    - ERRORä»¥ä¸Š: å¸¸ã«é€šã™
    - summaryã‚¿ã‚°ä»˜ã: é€šã™
    - ä¸Šè¨˜ä»¥å¤–ã®WARNING: åŸå‰‡é€šã™ãŒã€
      ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å†…éƒ¨ã®è©³ç´°è­¦å‘Šï¼ˆduplicate_prevention ç­‰ï¼‰ã¯ãƒã‚¤ã‚ºã®ãŸã‚æŠ‘åˆ¶
    - INFO/DEBUG: æŠ‘åˆ¶
    """

    def __init__(self, quiet: bool = True):
        super().__init__()
        self.quiet = quiet

    def _is_internal_mapping_warning(self, record: logging.LogRecord) -> bool:
        """ãƒãƒƒãƒ”ãƒ³ã‚°å†…éƒ¨ã®è©³ç´°è­¦å‘Šã‹åˆ¤å®šï¼ˆquietã§ã¯æŠ‘åˆ¶å¯¾è±¡ï¼‰ã€‚"""
        name = getattr(record, "name", "")
        if name.startswith("form_sender.analyzer.duplicate_prevention"):
            return True
        # æ—¢çŸ¥ã®è©³ç´°è­¦å‘Šæ–‡è¨€ã§ã‚‚æŠ‘åˆ¶ï¼ˆå°†æ¥ã®åç§°å¤‰æ›´ã«è€æ€§ï¼‰
        msg = str(getattr(record, "msg", "")).lower()
        if any(
            keyword in msg
            for keyword in [
                "duplicate value detected",
                "field group conflict detected",
            ]
        ):
            return True
        return False

    def filter(self, record: logging.LogRecord) -> bool:  # type: ignore[override]
        if not self.quiet:
            return True

        # ã‚¨ãƒ©ãƒ¼ä»¥ä¸Šã¯å¸¸ã«é€šã™
        if record.levelno >= logging.ERROR:
            return True

        # ã‚µãƒãƒªæŒ‡å®šã¯é€šã™
        if bool(getattr(record, "summary", False)):
            return True

        # WARNING ã¯åŸå‰‡é€šã™ãŒã€å†…éƒ¨è©³ç´°è­¦å‘Šã¯æŠ‘åˆ¶
        if record.levelno == logging.WARNING:
            return not self._is_internal_mapping_warning(record)

        # INFO/DEBUG ã¯quietã§ã¯è¡¨ç¤ºã—ãªã„
        return False


def configure_logging(verbose: bool = False, debug: bool = False) -> None:
    """ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã‚’å†æ§‹æˆã€‚quiet(æ—¢å®š)/verbose/debug ã‚’åˆ‡æ›¿ã€‚"""
    level = logging.DEBUG if debug else (logging.INFO if verbose else logging.INFO)
    quiet = not (verbose or debug)

    root = logging.getLogger()
    for h in list(root.handlers):
        root.removeHandler(h)

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(
        SanitizingFormatter("%(asctime)s - %(levelname)s - %(message)s")
    )
    if quiet:
        handler.addFilter(SummaryOnlyFilter(quiet=True))

    root.addHandler(handler)
    root.setLevel(level)


class FieldMappingAnalyzer:
    """ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ç²¾åº¦æ¤œè¨¼ãƒ„ãƒ¼ãƒ«"""

    def __init__(self):
        self.playwright = None
        self.browser = None
        self.context = None
        self.page = None
        self.supabase_client = None
        self._initialized = False
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé…ä¸‹ã«ãƒ†ã‚¹ãƒˆçµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        project_root = Path(__file__).parent.parent
        test_results_dir = project_root / "test_results" / f"field_mapping_{timestamp}"
        test_results_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir = str(test_results_dir)

    async def __aenter__(self):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼é–‹å§‹"""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼çµ‚äº† - ç¢ºå®Ÿãªãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        await self.cleanup()
        return False

    async def initialize(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        if self._initialized:
            logger.warning("Already initialized, skipping...")
            return

        try:
            # Supabaseæ¥ç¶šåˆæœŸåŒ–
            await self._initialize_supabase()

            # PlaywrightåˆæœŸåŒ–ï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼‰
            await self._initialize_browser()

            self._initialized = True
            logger.info("âœ… FieldMappingAnalyzer initialized successfully")

        except Exception as e:
            logger.error(f"âŒ Initialization failed: {e}")
            await self.cleanup()  # éƒ¨åˆ†çš„åˆæœŸåŒ–ã§ã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            raise

    async def _initialize_supabase(self):
        """Supabaseæ¥ç¶šåˆæœŸåŒ–"""
        try:
            from dotenv import load_dotenv

            # OS ç’°å¢ƒã«åŒåå¤‰æ•°ãŒå­˜åœ¨ã—ã¦ã‚‚ .env ã®å€¤ã‚’å„ªå…ˆ
            load_dotenv(override=True)

            supabase_url = os.getenv("SUPABASE_URL")
            supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

            if not supabase_url or not supabase_key:
                raise ValueError("Supabase credentials not found in environment")

            self.supabase_client = create_client(supabase_url, supabase_key)

        except Exception as e:
            logger.error(f"âŒ Supabase initialization failed: {e}")
            raise

    async def _initialize_browser(self):
        """PlaywrightåˆæœŸåŒ–ï¼ˆå®‰å®šåŒ–ï¼‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼‰"""
        try:
            self.playwright = await async_playwright().start()
            # ç’°å¢ƒå¤‰æ•°ã§GUI/ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ã«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼‰
            headless_env = os.getenv("PLAYWRIGHT_HEADLESS", "1").lower()
            headless = not (headless_env in ["0", "false", "no"])

            # ãƒ–ãƒ©ã‚¦ã‚¶ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: chromiumï¼‰ã€‚å•é¡Œç™ºç”Ÿæ™‚ã«åˆ‡æ›¿å¯èƒ½ã€‚
            engine = os.getenv("PLAYWRIGHT_ENGINE", "chromium").lower()
            engine_map = {
                "chromium": self.playwright.chromium,
                "webkit": self.playwright.webkit,
                "firefox": self.playwright.firefox,
            }
            launcher = engine_map.get(engine, self.playwright.chromium)
            if engine not in engine_map:
                logger.warning(
                    f"Unknown PLAYWRIGHT_ENGINE='{engine}', falling back to chromium"
                )

            # Chromium ã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã‚„ã™ã„ãƒ•ãƒ©ã‚°ã‚’æ•´ç†ã—ã€æœ€å°é™ã®å®‰å®šæ§‹æˆã«ã™ã‚‹
            # - macOS ã§ã¯ sandbox ç³»ãƒ•ãƒ©ã‚°ã¯ä¸è¦ï¼ˆLinux CI ã®ã¿ã«é™å®šï¼‰
            # - ä¸€éƒ¨ã® disable-* ãƒ•ãƒ©ã‚°ã¯æç”»/IPC å‘¨ã‚Šã®ä¸æ•´åˆã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’èª˜ç™ºã™ã‚‹ãŸã‚é™¤å»
            extra_args = []
            if engine == "chromium":
                import sys

                is_linux = sys.platform.startswith("linux")
                # æœ€å°ãƒ»å®‰å…¨å¯„ã‚Šã®ãƒ•ãƒ©ã‚°ã®ã¿é©ç”¨
                extra_args = [
                    "--disable-dev-shm-usage",
                    "--disable-blink-features=AutomationControlled",
                ]
                # Linux CI ã®ã¿ sandbox ç„¡åŠ¹åŒ–
                if is_linux:
                    extra_args += ["--no-sandbox", "--disable-setuid-sandbox"]
                # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹æ™‚ã®ã¿ GPU ã‚’æŠ‘åˆ¶ï¼ˆæç”»å‘¨ã‚Šã®å®‰å®šåŒ–ï¼‰
                if headless:
                    extra_args += ["--disable-gpu"]
            else:
                # Firefox/WebKit ã¯æ—¢å­˜ã®å®‰å®šæŒ™å‹•ã«å§”ã­ã‚‹ï¼ˆè¿½åŠ ãƒ•ãƒ©ã‚°ãªã—ï¼‰
                extra_args = []

            # Chromium ãŒç’°å¢ƒä¾å­˜ã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹ã‚±ãƒ¼ã‚¹ã«å‚™ãˆã€
            # ã¾ãšã‚·ã‚¹ãƒ†ãƒ  Chrome ãƒãƒ£ãƒ³ãƒãƒ«ã§ã®èµ·å‹•ã‚’è©¦ã¿ã€å¤±æ•—ã—ãŸã‚‰åŒãƒã‚¤ãƒŠãƒªã§å†è©¦è¡Œ
            launch_kwargs = dict(headless=headless, args=extra_args)
            if engine == "chromium":
                try:
                    self.browser = await launcher.launch(
                        channel="chrome", **launch_kwargs
                    )
                except Exception:
                    self.browser = await launcher.launch(**launch_kwargs)
            else:
                self.browser = await launcher.launch(**launch_kwargs)
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‹ãƒšãƒ¼ã‚¸ä½œæˆï¼ˆãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ã‚ºæ™‚ã®å¾©æ—§ã‚’å®¹æ˜“ã«ã™ã‚‹ï¼‰
            self.context = await self.browser.new_context(
                ignore_https_errors=True,
                java_script_enabled=True,
                bypass_csp=True,
                viewport={"width": 1366, "height": 900},
            )

            # ã„ãã¤ã‹ã®ã‚µã‚¤ãƒˆã§ç™ºç”Ÿã™ã‚‹ self-closing/popup ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå¯¾ç­–
            # - window.close ã‚’ç„¡åŠ¹åŒ–
            # - window.open ã¯åŒä¸€ã‚¿ãƒ–é·ç§»ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            await self.context.add_init_script(
                """
                (() => {
                  try {
                    const noop = () => false;
                    Object.defineProperty(window, 'close', { value: noop, configurable: true });
                    const _open = window.open;
                    Object.defineProperty(window, 'open', { value: (url, target, features) => {
                      try { window.location.href = url; } catch {}
                      return window;
                    }, configurable: true });
                  } catch {}
                })();
                """
            )

            # ãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ã‚ºã‚’æ¤œçŸ¥ã—ã¦è‡ªå‹•ã§æ–°è¦ãƒšãƒ¼ã‚¸ã‚’è£œå……
            self.context.set_default_navigation_timeout(30000)
            self.page = await self.context.new_page()
            self.page.on("close", lambda: logger.debug("Active page closed (event)"))

            # ä¸è¦ãƒªã‚½ãƒ¼ã‚¹ã®ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼ˆé€Ÿåº¦æœ€é©åŒ–ï¼‰ã€‚
            # ä»¥å‰ã¯ script ã‚’å³ã—ããƒ–ãƒ­ãƒƒã‚¯ã—ã¦ã„ãŸãŒã€
            # å‹•çš„ç”Ÿæˆãƒ•ã‚©ãƒ¼ãƒ ï¼ˆä¾‹: å¤–éƒ¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰ã§è¦ç´ ãŒç”Ÿæˆã•ã‚Œãªã„å•é¡ŒãŒç™ºç”Ÿã€‚
            # æ±ç”¨ç²¾åº¦ã‚’å„ªå…ˆã— script ã¯è¨±å¯ã—ã€æ˜ã‚‰ã‹ãªãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç³»ã®ã¿æŠ‘åˆ¶ã™ã‚‹ã€‚
            async def handle_route(route):
                resource_type = route.request.resource_type
                url = route.request.url.lower()

                # ç”»åƒãƒ»ãƒ•ã‚©ãƒ³ãƒˆãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢ã¯å¼•ãç¶šãé®æ–­ï¼ˆDOMè§£æã«ä¸è¦ï¼‰
                if resource_type in ["image", "media", "font", "manifest", "other"]:
                    await route.abort()
                    return

                # CSS ã¯åŸºæœ¬ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆè¡¨ç¤ºå´©ã‚Œã‚ˆã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å„ªå…ˆï¼‰ã€‚
                # ãŸã ã—ãƒ•ã‚©ãƒ¼ãƒ ç”Ÿæˆã« CSS ã¯ä¸è¦ãªãŸã‚è¨±å®¹ãƒªã‚¹ã‚¯ã¯ä½ã„ã€‚
                if resource_type == "stylesheet":
                    await route.abort()
                    return

                # Script ã¯è¨±å¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ç”Ÿæˆã®ãŸã‚ï¼‰ã€‚
                # ãŸã ã—æ˜ç¢ºãªãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ»åºƒå‘Šç³»ã®ã¿ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦ãƒã‚¤ã‚ºã‚’ä½æ¸›ã€‚
                if resource_type == "script":
                    tracker_keywords = [
                        "googletagmanager.com",
                        "google-analytics.com",
                        "www.google-analytics.com",
                        "doubleclick.net",
                        "googlesyndication.com",
                        "facebook.net",
                        "connect.facebook.net",
                        "hotjar.com",
                        "mixpanel.com",
                        "amplitude.com",
                    ]
                    if any(k in url for k in tracker_keywords):
                        await route.abort()
                        return

                # ãã®ä»–ã¯è¨±å¯
                await route.continue_()

            # ä»¥é™ã«ç”Ÿæˆã•ã‚Œã‚‹ãƒšãƒ¼ã‚¸ã«ã‚‚é©ç”¨ã•ã‚Œã‚‹ã‚ˆã† Context ã«é©ç”¨
            await self.context.route("**/*", handle_route)

            # User Agentè¨­å®šï¼ˆContextå˜ä½ã§é©ç”¨ï¼‰
            await self.context.set_extra_http_headers(
                {
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                }
            )

            mode = "headless" if headless else "headed"
            logger.info(f"âœ… Browser initialized with memory optimization ({mode})")

        except Exception as e:
            logger.error(f"âŒ Browser initialization failed: {e}")
            # éƒ¨åˆ†çš„åˆæœŸåŒ–ã§ã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.page:
                try:
                    await self.page.close()
                except:
                    pass
            if self.context:
                try:
                    await self.context.close()
                except:
                    pass
            if self.browser:
                try:
                    await self.browser.close()
                except:
                    pass
            if self.playwright:
                try:
                    await self.playwright.stop()
                except:
                    pass
            raise

    async def _recreate_page(self, max_retries: int = 2) -> None:
        """ãƒšãƒ¼ã‚¸/ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–‰é–æ™‚ã®ç°¡æ˜“ãƒªã‚«ãƒãƒªï¼ˆæœ€å¤§ max_retries å›ï¼‰ã€‚"""
        import asyncio

        last_err = None
        for attempt in range(max_retries):
            try:
                if self.page:
                    try:
                        await self.page.close()
                    except Exception:
                        pass
                if self.context is None:
                    if self.browser is None:
                        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚‚ç„¡ã„å ´åˆã¯å†åˆæœŸåŒ–
                        await self._initialize_browser()
                        return
                    # åˆæœŸåŒ–æ™‚ã¨åŒç­‰ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å†é©ç”¨
                    self.context = await self.browser.new_context(
                        ignore_https_errors=True,
                        java_script_enabled=True,
                        bypass_csp=True,
                        viewport={"width": 1366, "height": 900},
                    )

                    # self-closing / popup æŠ‘æ­¢ init_script ã‚’æœ€å„ªå…ˆã§å†é©ç”¨
                    await self.context.add_init_script(
                        """
                        (() => { try {
                          const noop = () => false;
                          Object.defineProperty(window, 'close', { value: noop, configurable: true });
                          const _open = window.open;
                          Object.defineProperty(window, 'open', { value: (url, target, features) => {
                            try { window.location.href = url; } catch {}
                            return window;
                          }, configurable: true });
                        } catch {} })();
                        """
                    )

                    # User-Agent / ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå†è¨­å®š
                    await self.context.set_extra_http_headers(
                        {
                            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                        }
                    )
                    self.context.set_default_navigation_timeout(30000)

                    # å†ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼ˆåˆæœŸåŒ–æ™‚ã¨åŒæ§˜ã®ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°æ–¹é‡ï¼‰
                    async def handle_route(route):
                        resource_type = route.request.resource_type
                        url = route.request.url.lower()
                        if resource_type in [
                            "image",
                            "media",
                            "font",
                            "manifest",
                            "other",
                        ]:
                            await route.abort()
                            return
                        if resource_type == "stylesheet":
                            await route.abort()
                            return
                        if resource_type == "script":
                            tracker_keywords = [
                                "googletagmanager.com",
                                "google-analytics.com",
                                "www.google-analytics.com",
                                "doubleclick.net",
                                "googlesyndication.com",
                                "facebook.net",
                                "connect.facebook.net",
                                "hotjar.com",
                                "mixpanel.com",
                                "amplitude.com",
                            ]
                            if any(k in url for k in tracker_keywords):
                                await route.abort()
                                return
                        await route.continue_()

                    await self.context.route("**/*", handle_route)

                # æ–°è¦ãƒšãƒ¼ã‚¸ç”Ÿæˆã¨ã‚¤ãƒ™ãƒ³ãƒˆå†è¨­å®š
                self.page = await self.context.new_page()
                self.page.on(
                    "close", lambda: logger.debug("Active page closed (event)")
                )
                return
            except Exception as e:
                last_err = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
        # å¤±æ•—æ™‚ã¯æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦å®Œå…¨å†åˆæœŸåŒ–
        await self.cleanup()
        await self.initialize()

    async def fetch_test_form_url(
        self, company_id: Optional[int] = None
    ) -> Optional[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆç”¨form_urlã‚’1ä»¶å–å¾—ï¼ˆæŒ‡å®šIDã¾ãŸã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼‰"""
        try:
            if company_id:
                logger.info(
                    f"Fetching specific company (ID: {company_id}) from database...",
                    extra={"summary": True},
                )

                # æŒ‡å®šã•ã‚ŒãŸIDã®ä¼æ¥­ã‚’å–å¾—
                # ãƒ•ã‚©ãƒ¼ãƒ URLã¯ http(s) ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹ï¼ˆmailtoç­‰ã§ã®ãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†å›é¿ï¼‰
                response = (
                    self.supabase_client.table("companies")
                    .select("id, company_name, form_url, instruction_json, company_url")
                    .eq("id", company_id)
                    .neq("form_url", None)
                    .ilike("form_url", "http%")
                    .limit(1)
                    .execute()
                )

                if not response.data:
                    logger.error(
                        f"Company with ID {company_id} not found or has no form_url"
                    )
                    return None

                company = response.data[0]
                logger.info("âœ… Specific company selected:")

            else:
                logger.info("Fetching random test form URL from database...")

                # ãƒ©ãƒ³ãƒ€ãƒ ãªIDã‚’ç”Ÿæˆï¼ˆ1-500000ã®ç¯„å›²ï¼‰
                random_id = random.randint(1, 500000)
                logger.info(f"Using random ID threshold: {random_id}")

                # form_urlã‚’æŒã¤ä¼æ¥­ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«1ä»¶å–å¾—
                # mailtoã‚„javascriptã‚¹ã‚­ãƒ¼ãƒ ã‚’é™¤å¤–ã—ã€å®Ÿãƒšãƒ¼ã‚¸ã®ã¿é¸æŠ
                response = (
                    self.supabase_client.table("companies")
                    .select("id, company_name, form_url, instruction_json, company_url")
                    .neq("form_url", None)
                    .ilike("form_url", "http%")
                    .gt("id", random_id)
                    .limit(1)
                    .execute()
                )

                if not response.data:
                    logger.warning("No companies with form_url found")
                    return None

                company = response.data[0]
                logger.info("âœ… Random test company selected:", extra={"summary": True})

            logger.info(
                f"ğŸ¯ Target company_id: {company['id']}", extra={"summary": True}
            )
            # ä¼šç¤¾åãƒ»URLãªã©ã¯ quiet ã§ã¯éè¡¨ç¤ºï¼ˆå¿…è¦ãªã‚‰ --verbose/--debugï¼‰
            logger.info(f"   Company: ***COMPANY_REDACTED***")
            logger.info(f"   Form URL: ***URL_REDACTED***")
            logger.info(
                f"   Has instruction: {'Yes' if company.get('instruction_json') else 'No'}"
            )

            return company

        except Exception as e:
            logger.error(f"âŒ Failed to fetch test form URL: {e}")
            return None

    async def _analyze_form_mapping_once(
        self, form_url: str
    ) -> Tuple[Dict[str, Any], str]:
        """ãƒ•ã‚©ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è§£æå®Ÿè¡Œï¼ˆå˜å›å®Ÿè¡Œï¼‰"""
        logger.info(f"Starting form mapping analysis...", extra={"summary": True})
        logger.info(f"Target URL: ***URL_REDACTED***")

        try:
            # Step 1: ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—/ã‚»ãƒ«ãƒ•ã‚¯ãƒ­ãƒ¼ã‚ºã«å¼·ã„å®Ÿè£…ï¼‰
            # å…ˆã«ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ç›£è¦–ã‚’ä»•è¾¼ã‚€ï¼ˆonce ã§è‡ªå‹•è§£é™¤ï¼‰ã€‚
            popup_captured: List[Page] = []

            def _on_popup(p):
                try:
                    popup_captured.append(p)
                    logger.debug("Popup captured during navigation")
                except Exception:
                    pass

            self.page.once("popup", _on_popup)

            try:
                await self.page.goto(
                    form_url, wait_until="domcontentloaded", timeout=25000
                )
            except Exception as e:
                # æ—§ãƒšãƒ¼ã‚¸ãŒé–‰ã˜ã‚‰ã‚ŒãŸå ´åˆã§ã‚‚ã€ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ãŒå–ã‚Œã¦ã„ã‚Œã°ãã¡ã‚‰ã‚’æ¡ç”¨
                if "has been closed" in str(e) and popup_captured:
                    try:
                        candidate = popup_captured[-1]
                        # æ—¢ã«é–‰ã˜ã¦ã„ãªã„ã‹ç¢ºèª
                        is_closed = False
                        try:
                            if hasattr(candidate, "is_closed"):
                                is_closed = bool(candidate.is_closed())
                        except Exception:
                            is_closed = False

                        if not is_closed:
                            self.page = candidate
                            logger.info("Detected self-close -> switched to popup page")
                        else:
                            logger.info(
                                "Captured popup already closed. Recreating page and retrying..."
                            )
                            await self._recreate_page()
                            await self.page.goto(
                                form_url, wait_until="domcontentloaded", timeout=25000
                            )
                    finally:
                        popup_captured.clear()
                elif "has been closed" in str(e):
                    logger.info(
                        "Detected unexpected page close. Recreating page and retrying once..."
                    )
                    await self._recreate_page()
                    await self.page.goto(
                        form_url, wait_until="domcontentloaded", timeout=25000
                    )
                else:
                    raise

            # DOMã®å®‰å®šåŒ–ã‚’æœ€å°é™ã®å¾…æ©Ÿã§ç¢ºä¿
            await asyncio.sleep(0.5)  # 500msã®æœ€å°å¾…æ©Ÿã§DOMå®‰å®šåŒ–

            # CookieåŒæ„ãƒãƒŠãƒ¼ãŒã‚ã‚Œã°å‡¦ç†
            await CookieConsentHandler.handle(self.page)

            # Step 2: ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            form_count = await self.page.evaluate(
                "document.querySelectorAll('form').length"
            )
            logger.info(f"ğŸ“‹ Initial form elements found: {form_count}")

            # HubSpotã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ¤œå‡º
            has_hubspot_script = await self.page.evaluate("""
                () => {
                    const scripts = Array.from(document.querySelectorAll('script'));
                    return scripts.some(script => 
                        script.src && (script.src.includes('hsforms.net') || script.src.includes('hubspot'))
                    );
                }
            """)

            if has_hubspot_script:
                logger.info(
                    "ğŸ” HubSpot forms script detected - applying specialized handling"
                )

            # Step 3: ãƒ•ã‚©ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¾ãŸã¯HubSpotãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿è¿½åŠ å¾…æ©Ÿ
            if form_count == 0 or has_hubspot_script:
                if form_count == 0:
                    logger.info(
                        "No form elements found with domcontentloaded, trying additional strategies..."
                    )
                else:
                    logger.info("HubSpot detected - ensuring complete form loading...")

                success = await self._wait_for_dynamic_content()
                if success:
                    form_count = await self.page.evaluate(
                        "document.querySelectorAll('form').length"
                    )
                    logger.info(
                        f"ğŸ“‹ Form elements found after dynamic waiting: {form_count}"
                    )

                    # HubSpotè¦ç´ ã®è©³ç´°ãƒã‚§ãƒƒã‚¯
                    if has_hubspot_script:
                        hubspot_info = await self.page.evaluate("""
                            () => {
                                const hbsptForms = document.querySelectorAll('.hbspt-form').length;
                                const hsInputs = document.querySelectorAll('.hs-input').length;
                                const hsFieldsets = document.querySelectorAll('fieldset.form-columns-1, fieldset.form-columns-2').length;
                                return {hbsptForms, hsInputs, hsFieldsets};
                            }
                        """)
                        logger.info(
                            f"ğŸ“‹ HubSpot elements: containers={hubspot_info['hbsptForms']}, inputs={hubspot_info['hsInputs']}, fieldsets={hubspot_info['hsFieldsets']}"
                        )

            # ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‹ã‚‰<form>è¦ç´ ã®ã¿ã‚’æŠ½å‡ºã—ã¦ä¿å­˜
            page_source = await self.page.content()
            form_content = self._extract_form_content(page_source)

            # iframeå†…ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã‚’æŠ½å‡ºã—ã€target_frameã‚‚åŒæ™‚ã«æ±ºå®šï¼ˆçµ±åˆå‡¦ç†ï¼‰
            target_frame = None
            if form_count == 0:  # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«formãŒãªã„å ´åˆã®ã¿ãƒã‚§ãƒƒã‚¯
                logger.info("ğŸ” No forms found in main page, checking iframes...")
                iframe_content, target_frame = await self._analyze_iframes()
                if iframe_content:
                    form_content += "\n\n" + iframe_content

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            source_file = os.path.join(self.temp_dir, f"page_source_{timestamp}.html")

            with open(source_file, "w", encoding="utf-8") as f:
                f.write(form_content)

            logger.info(
                f"ğŸ“„ Form content saved: {source_file}", extra={"summary": True}
            )

            # RuleBasedAnalyzerã§ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°å®Ÿè¡Œ
            if target_frame:
                analyzer = RuleBasedAnalyzer(target_frame)  # iframeå†…ã‚’è§£æ
                logger.info("ğŸ“‹ Analyzing iframe content for field mapping")
            else:
                analyzer = RuleBasedAnalyzer(self.page)  # é€šå¸¸ã®ãƒšãƒ¼ã‚¸ã‚’è§£æ
                logger.info("ğŸ“‹ Analyzing main page content for field mapping")

            # å…¥åŠ›å€¤ç”Ÿæˆã®ãŸã‚ã€client/targeting ã‚’å«ã‚€æ§‹é€ ä½“ã‚’æ¸¡ã™
            analysis_result = await analyzer.analyze_form(
                client_data=create_test_client_config()
            )

            # HTMLã‹ã‚‰å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’æŠ½å‡º
            required_fields_info = self._extract_required_fields(form_content)
            analysis_result["required_fields_info"] = required_fields_info

            return analysis_result, source_file

        except Exception as e:
            logger.error(f"âŒ Form mapping analysis failed: {e}")
            raise

    async def analyze_form_mapping(self, form_url: str) -> Tuple[Dict[str, Any], str]:
        """ãƒ•ã‚©ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è§£æå®Ÿè¡Œï¼ˆãƒšãƒ¼ã‚¸/ãƒ–ãƒ©ã‚¦ã‚¶ãŒé–‰ã˜ã‚‰ã‚ŒãŸå ´åˆã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤å¯¾å¿œï¼‰"""
        last_error: Optional[Exception] = None
        for attempt in range(2):
            try:
                return await self._analyze_form_mapping_once(form_url)
            except Exception as e:
                last_error = e
                if "has been closed" in str(e):
                    logger.info(
                        "Detected unexpected page/context/browser close. Recreating page and retrying once..."
                    )
                    await self._recreate_page()
                    continue
                raise
        # å†è©¦è¡Œã—ã¦ã‚‚å¤±æ•—ã—ãŸå ´åˆ
        raise last_error if last_error else RuntimeError("Form mapping analysis failed")

    def analyze_mapping_results(
        self, analysis_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã®è©³ç´°åˆ†æ"""
        logger.info("\n" + "=" * 80)
        logger.info("FIELD MAPPING ANALYSIS RESULTS")
        logger.info("=" * 80)

        field_mappings = analysis_result.get("field_mapping", {})
        total_fields = len(field_mappings)

        logger.info(f"ğŸ“Š Total mapped fields: {total_fields}")

        if total_fields == 0:
            logger.warning("âš ï¸  No fields were mapped!")
            return {"total_fields": 0, "issues": ["no_fields_mapped"]}

        # è©³ç´°ãªãƒãƒƒãƒ”ãƒ³ã‚°çµæœã‚’è¡¨ç¤º
        issues = []
        field_analysis = {}

        for field_name, field_info in field_mappings.items():
            logger.info(f"\nğŸ¯ Field: {field_name}")

            # ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æŠ½å‡º
            input_value = field_info.get("input_value", "N/A")
            score = field_info.get("score", 0)
            element = field_info.get("element", {})

            # Playwrightã®Locatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ vs è¾æ›¸å‹ã®åˆ¤åˆ¥
            element_type_name = str(type(element))
            element_str = str(element)

            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 
            logger.debug(
                f"Element type: {element_type_name}, Element str: {element_str[:100]}..."
            )

            if "Locator" in element_type_name or "Locator" in element_str:
                # Playwrightã®Locatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                element_name = element_str
                element_id = "Locator-Object"
                element_type = "Locator"
                selector = element_str
            elif isinstance(element, dict):
                # è¾æ›¸å‹ã®å ´åˆï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã®ã‚µãƒãƒ¼ãƒˆï¼‰
                element_name = element.get("name", "N/A")
                element_id = element.get("id", "N/A")
                element_type = element.get("type", "N/A")
                selector = element.get("selector", "N/A")
            else:
                # ãã®ä»–ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                element_name = element_str
                element_id = "Unknown"
                element_type = (
                    element_type_name.split("'")[1]
                    if "'" in element_type_name
                    else "Unknown"
                )
                selector = element_str

            logger.info(f"   Input Value: '{input_value}'")
            logger.info(f"   Score: {score}")
            logger.info(f"   Element Type: {element_type}")
            logger.info(f"   Selector: {selector}")

            # Locatorã®å ´åˆã¯ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æä¾›
            if "Locator" in element_type:
                # Locatorã‹ã‚‰æœ‰ç”¨ãªæƒ…å ±ã‚’æŠ½å‡º
                if "selector=" in element_str:
                    try:
                        # selector='...' ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                        selector_start = element_str.find("selector='") + len(
                            "selector='"
                        )
                        selector_end = element_str.find("'>", selector_start)
                        if selector_end > selector_start:
                            extracted_selector = element_str[
                                selector_start:selector_end
                            ]
                            logger.info(f"   Extracted Selector: {extracted_selector}")
                    except Exception:
                        pass

                logger.info(f"   Full Locator: {element_str}")
            else:
                logger.info(
                    f"   Target Element: name='{element_name}', id='{element_id}'"
                )

            # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            field_issues = self._check_field_issues(field_name, field_info)
            if field_issues:
                issues.extend(field_issues)

            field_analysis[field_name] = {
                "value": field_info.get("value", ""),
                "score": field_info.get("score", 0),
                "issues": field_issues,
            }

        # form_sender_nameä½¿ç”¨ãƒã‚§ãƒƒã‚¯
        if "form_sender_name" in field_mappings or any(
            "form_sender_name" in str(info) for info in field_mappings.values()
        ):
            issues.append("deprecated_form_sender_name_used")
            logger.warning("âš ï¸  Deprecated form_sender_name detected!")

        # é‡è¤‡å€¤ãƒã‚§ãƒƒã‚¯
        value_counts = {}
        for field_name, field_info in field_mappings.items():
            value = field_info.get("value", "")
            if value and value.strip():
                value_counts[value] = value_counts.get(value, 0) + 1

        duplicates = {v: count for v, count in value_counts.items() if count > 1}
        if duplicates:
            # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ç¢ºèªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é™¤ãé‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯
            non_email_duplicates = {
                v: count
                for v, count in duplicates.items()
                if not self._is_email_confirmation_value(v)
            }
            if non_email_duplicates:
                issues.append("duplicate_values_found")
                # å€¤ã¯ãƒ­ã‚°ã«å‡ºã•ãªã„ï¼ˆå€‹äººæƒ…å ±ä¿è­·ï¼‰ã€‚ä»¶æ•°ã®ã¿é€šçŸ¥ã€‚
                logger.warning(
                    f"âš ï¸  Non-email duplicate values found (count={len(non_email_duplicates)})",
                    extra={"summary": True},
                )

        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ã¯å‹•çš„æ¤œå‡ºã•ã‚ŒãŸæƒ…å ±ã‚’ä½¿ç”¨
        # ï¼ˆè©³ç´°ãªè©•ä¾¡ã¯field-mapping-evaluatorã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Ÿè¡Œï¼‰
        required_info = analysis_result.get("required_fields_info", {})
        if required_info and not required_info.get("error"):
            required_count = required_info.get("required_fields_count", 0)
            logger.info(f"ğŸ“‹ Required fields detected: {required_count} fields")

            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç°¡å˜ãªä¸€è¦§è¡¨ç¤ºï¼ˆè©³ç´°è©•ä¾¡ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å§”è­²ï¼‰
            for req_element in required_info.get("required_elements", []):
                label = req_element.get(
                    "label_text",
                    req_element.get("placeholder", req_element.get("name", "N/A")),
                )
                logger.info(f"   - Required: {label}")

        logger.info(f"\nğŸ“‹ Basic Analysis Summary:")
        logger.info(f"   Total mapped fields: {total_fields}")
        logger.info(f"   Basic issues found: {len(issues)}")
        if issues:
            logger.info(f"   Issue types: {', '.join(set(issues))}")
        logger.info(
            "   â„¹ï¸  Detailed evaluation will be performed by field-mapping-evaluator agent"
        )

        return {
            "total_fields": total_fields,
            "issues": issues,
            "field_analysis": field_analysis,
            "duplicates": duplicates,
            "required_fields_info": required_info,
        }

    def _check_field_issues(
        self, field_name: str, field_info: Dict[str, Any]
    ) -> List[str]:
        """å€‹åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å•é¡Œãƒã‚§ãƒƒã‚¯"""
        issues = []
        value = field_info.get("value", "")
        score = field_info.get("score", 0)

        # ä½ã‚¹ã‚³ã‚¢ãƒã‚§ãƒƒã‚¯
        if score < 15:
            issues.append("low_confidence_score")

        # ä¸é©åˆ‡ãªå€¤ã®ä¾‹ï¼ˆäº”ååµå•é¡Œç­‰ï¼‰
        if field_name in ["ä¼šç¤¾å", "company_name"] and any(
            name in value for name in ["äº”ååµ", "é§¿", "ã„ãŒã‚‰ã—", "ã—ã‚…ã‚“"]
        ):
            issues.append("name_in_company_field")

        if (
            field_name in ["å§“", "å", "last_name", "first_name"]
            and "æ ªå¼ä¼šç¤¾" in value
        ):
            issues.append("company_in_name_field")

        return issues

    def _is_email_confirmation_value(self, value: str) -> bool:
        """ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ç¢ºèªå€¤ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯"""
        return "@" in value and "neurify.jp" in value.lower()

    def _make_json_serializable(self, obj: Any) -> Any:
        """JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif hasattr(obj, "__dict__"):
            # Locatorãªã©ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯æ–‡å­—åˆ—è¡¨ç¾ã«å¤‰æ›
            return str(obj)
        else:
            return obj

    # ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ è¡¨ç¤ºãƒ¡ã‚½ãƒƒãƒ‰ã¯å‰Šé™¤ï¼ˆpage_sourceãƒ•ã‚¡ã‚¤ãƒ«ã§ä»£æ›¿ï¼‰

    def _log_memory_usage(self, phase: str):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ­ã‚°"""
        try:
            import psutil

            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            logger.info(f"ğŸ’¾ Memory usage ({phase}): {memory_mb:.1f} MB")
        except ImportError:
            logger.debug("psutil not available for memory monitoring")
        except Exception:
            pass

    async def run_single_test(self, company_id: Optional[int] = None) -> bool:
        """å˜ä¸€ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self._log_memory_usage("start")

        try:
            # ãƒ†ã‚¹ãƒˆå¯¾è±¡ä¼æ¥­ã‚’å–å¾—
            test_company = await self.fetch_test_form_url(company_id)
            if not test_company:
                logger.error("No test company available")
                return False

            form_url = test_company["form_url"]

            # ãƒ•ã‚©ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è§£æå®Ÿè¡Œ
            self._log_memory_usage("before_analysis")
            analysis_result, source_file = await self.analyze_form_mapping(form_url)
            self._log_memory_usage("after_analysis")

            # çµæœåˆ†æ
            analysis_summary = self.analyze_mapping_results(analysis_result)

            # ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ è¡¨ç¤ºã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆpage_sourceãƒ•ã‚¡ã‚¤ãƒ«ã§ååˆ†ï¼‰

            # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = os.path.join(
                self.temp_dir, f"analysis_result_{timestamp}.json"
            )

            # JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®çµæœã‚’æº–å‚™ï¼ˆLocatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é™¤å¤–ï¼‰
            serializable_result = self._make_json_serializable(analysis_result)

            result_data = {
                "company_id": test_company["id"],
                "form_url": form_url,
                "timestamp": timestamp,
                "analysis_result": serializable_result,
                "analysis_summary": analysis_summary,
                "source_file": source_file,
                "test_metadata": {
                    "company_id": test_company["id"],
                    "is_specific_id_test": test_company["id"] is not None,
                    "test_timestamp": timestamp,
                },
            }

            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)

            logger.info(
                f"\nğŸ’¾ Analysis result saved: {result_file}", extra={"summary": True}
            )
            logger.info(f"ğŸ“„ Page source saved: {source_file}", extra={"summary": True})

            self._log_memory_usage("end")

            # æ”¹å–„ææ¡ˆã¯è‡ªå‹•åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å§”è­²

            return True

        except Exception as e:
            logger.error(f"âŒ Single test execution failed: {e}")
            return False

    def _extract_required_fields(self, form_content: str) -> Dict[str, Any]:
        """HTMLã‹ã‚‰å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’å‹•çš„ã«æŠ½å‡º"""
        try:
            if not HAS_BEAUTIFULSOUP:
                return {
                    "error": "BeautifulSoup not available for required field detection"
                }

            soup = BeautifulSoup(form_content, "html.parser")
            required_elements = []

            # 0. hiddenãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å«ã¾ã‚Œã‚‹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ’ãƒ³ãƒˆã‚’æ¤œå‡º
            # ä¾‹: <input type="hidden" name="F2M_CHECK_01" value="NAME,ãŠåå‰ã¯å¿…é ˆã§ã™">
            hinted_names_upper = []
            try:
                for h in soup.find_all("input", {"type": "hidden"}):
                    name_attr = (h.get("name") or "").upper()
                    value_attr = (h.get("value") or "")
                    if any(k in name_attr for k in ["F2M_CHECK", "REQ_CHECK", "REQUIRED_CHECK", "VALIDATE_"]):
                        if "," in value_attr:
                            candidate = value_attr.split(",", 1)[0].strip()
                            if 0 < len(candidate) <= 64:
                                hinted_names_upper.append(candidate.upper())
            except Exception:
                pass
            # é‡è¤‡æ’é™¤
            hinted_names_upper = list(dict.fromkeys(hinted_names_upper))

            # requiredå±æ€§ã€aria-required="true"ã€ã‚¯ãƒ©ã‚¹åã€éš£æ¥è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            for element in soup.find_all(["input", "textarea", "select"]):
                is_required = False

                # 1. requiredå±æ€§ã®ãƒã‚§ãƒƒã‚¯
                if element.get("required") is not None:
                    is_required = True

                # 2. aria-requiredå±æ€§ã®ãƒã‚§ãƒƒã‚¯
                elif element.get("aria-required") == "true":
                    is_required = True

                # 3. ã‚¯ãƒ©ã‚¹åã«ã‚ˆã‚‹å¿…é ˆåˆ¤å®š
                elif self._check_required_by_class(element):
                    is_required = True

                # 4. éš£æ¥è¦ç´ ã®å¿…é ˆãƒãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
                elif self._check_required_by_adjacent_text(element):
                    is_required = True

                # 5. hiddenãƒ’ãƒ³ãƒˆï¼ˆåå‰ä¸€è‡´ï¼‰
                elif hinted_names_upper:
                    try:
                        elem_name = (element.get("name") or "").strip()
                        if elem_name and elem_name.upper() in hinted_names_upper:
                            is_required = True
                    except Exception:
                        pass

                if is_required:
                    element_info = {
                        "tag": element.name,
                        "name": element.get("name", ""),
                        "id": element.get("id", ""),
                        "type": element.get("type", ""),
                        "placeholder": element.get("placeholder", ""),
                        "class": " ".join(element.get("class", [])),
                    }
                    required_elements.append(element_info)

            # ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚‚æŠ½å‡º
            for req_element in required_elements:
                element_id = req_element.get("id")
                element_name = req_element.get("name")

                # labelè¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                label_text = ""
                if element_id:
                    label = soup.find("label", {"for": element_id})
                    if label:
                        label_text = label.get_text(strip=True)

                # placeholder ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚‚å«ã‚ã‚‹
                if req_element.get("placeholder"):
                    if label_text:
                        label_text += f" ({req_element['placeholder']})"
                    else:
                        label_text = req_element["placeholder"]

                req_element["label_text"] = label_text

            return {
                "required_fields_count": len(required_elements),
                "required_elements": required_elements,
                "detection_method": "comprehensive_required_detection",
            }

        except Exception as e:
            return {"error": f"Required field extraction failed: {e}"}

    def _check_required_by_class(self, element) -> bool:
        """ã‚¯ãƒ©ã‚¹åã«ã‚ˆã‚‹å¿…é ˆåˆ¤å®š"""
        class_attr = element.get("class", [])
        if isinstance(class_attr, list):
            class_names = " ".join(class_attr).lower()
        else:
            class_names = str(class_attr).lower()

        # å¿…é ˆã‚’ç¤ºã™ã‚¯ãƒ©ã‚¹åãƒ‘ã‚¿ãƒ¼ãƒ³
        required_class_patterns = [
            "fldrequired",  # CFormsãƒ—ãƒ©ã‚°ã‚¤ãƒ³
            "wpcf7-validates-as-required",  # Contact Form 7
            "required",
            "mandatory",
            "must",
        ]

        return any(pattern in class_names for pattern in required_class_patterns)

    def _check_required_by_adjacent_text(self, element) -> bool:
        """éš£æ¥è¦ç´ ã®å¿…é ˆãƒãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯"""
        try:
            # æ¬¡ã®å…„å¼Ÿè¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            next_sibling = element.next_sibling
            while next_sibling:
                # <img alt="å¿…é ˆ"> ã«å¯¾å¿œ
                try:
                    if getattr(next_sibling, 'name', '') == 'img':
                        alt = (next_sibling.get('alt') or '').strip()
                        if any(m in alt for m in ["å¿…é ˆ", "Required", "Mandatory"]):
                            return True
                except Exception:
                    pass
                if hasattr(next_sibling, "get_text"):
                    text = next_sibling.get_text().strip()
                    # ãƒ©ãƒ™ãƒ«è¿‘å‚ã§ã¯ã€â€»ã€ãŒå¿…é ˆè¨˜å·ã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚
                    # ãŸã ã—æ³¨è¨˜ã¨ã®æ··åŒã‚’é¿ã‘ã‚‹ãŸã‚ã€çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã«é™å®šã—ã¦è¨±å¯ã™ã‚‹ã€‚
                    if any(marker in text for marker in ["å¿…é ˆ", "Required", "Mandatory", "*", "ï¼Š"]):
                        return True
                    if "â€»" in text and len(text) <= 10:
                        return True
                next_sibling = next_sibling.next_sibling

            # è¦ªè¦ç´ å†…ã®ä»–ã®å­è¦ç´ ã‚‚ãƒã‚§ãƒƒã‚¯
            if element.parent:
                for sibling in element.parent.find_all(["span", "label", "div", "img"]):
                    if sibling != element:
                        if getattr(sibling, 'name', '') == 'img':
                            try:
                                alt = (sibling.get('alt') or '').strip()
                                if any(m in alt for m in ["å¿…é ˆ", "Required", "Mandatory"]):
                                    return True
                            except Exception:
                                pass
                        else:
                            text = sibling.get_text().strip()
                            if (any(marker in text for marker in ["å¿…é ˆ", "Required", "Mandatory"]) or "â€»" in text) and len(text) <= 10:
                                return True

            # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¯¾å¿œ: tdå†…ã®inputã«å¯¾ã—ã¦ç›´å‰ã®thã‚’ç¢ºèª
            try:
                td = element
                # ç¥–å…ˆæ–¹å‘ã«è¾¿ã£ã¦ td ã‚’æ¢ã™
                while td and getattr(td, "name", "") != "td":
                    td = td.parent
                if td and td.parent:
                    # åŒã˜ tr å†…ã®ç›´å‰ th ã‚’æ¢ã™
                    prev = td.find_previous_sibling("th")
                    if prev:
                        th_text = prev.get_text().strip()
                        if any(marker in th_text for marker in ["å¿…é ˆ", "Required", "Mandatory", "ï¼Š", "*", "â€»"]):
                            return True
                        # th å†…ã®ç”»åƒ alt ã§ã‚‚å¿…é ˆã‚’æ¤œå‡º
                        try:
                            for img in prev.find_all("img"):
                                alt = (img.get('alt') or '').strip()
                                if any(m in alt for m in ["å¿…é ˆ", "Required", "Mandatory"]):
                                    return True
                        except Exception:
                            pass
            except Exception:
                pass

            return False

        except Exception:
            return False

    async def _wait_for_dynamic_content(self, max_wait: int = 15) -> bool:
        """å‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ®µéšçš„ã«å¾…æ©Ÿï¼ˆHubSpotå¯¾å¿œå¼·åŒ–ï¼‰"""
        logger.info("ğŸ”„ Waiting for dynamic content...")

        # æˆ¦ç•¥1: HubSpotãƒ•ã‚©ãƒ¼ãƒ ç‰¹æœ‰ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒã‚§ãƒƒã‚¯
        try:
            logger.info("Strategy 1: HubSpot form detection...")
            hubspot_selectors = [
                ".hbspt-form form",
                'form[id^="hsForm_"]',
                "div[data-hs-forms-root] form",
                ".hs-form",
                'div[id^="hbspt-form-"] form',
            ]

            for selector in hubspot_selectors:
                try:
                    count = await self.page.evaluate(
                        f'document.querySelectorAll("{selector}").length'
                    )
                    if count > 0:
                        logger.info(
                            f"âœ… HubSpot form detected with selector '{selector}': {count} forms"
                        )
                        return True
                except Exception:
                    continue

            # HubSpotã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            has_hubspot_script = await self.page.evaluate("""
                () => {
                    const scripts = Array.from(document.querySelectorAll('script'));
                    return scripts.some(script => 
                        script.src && (script.src.includes('hsforms.net') || script.src.includes('hubspot'))
                    );
                }
            """)

            if has_hubspot_script:
                logger.info("HubSpot script detected, applying extended wait...")

        except Exception as e:
            logger.debug(f"HubSpot detection failed: {e}")

        # æˆ¦ç•¥2: æ‹¡å¼µnetworkidleå¾…æ©Ÿï¼ˆHubSpotå¯¾å¿œï¼‰
        try:
            logger.info("Strategy 2: Extended networkidle wait...")
            await self.page.wait_for_load_state("networkidle", timeout=15000)

            # ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            form_count = await self.page.evaluate(
                "document.querySelectorAll('form').length"
            )
            if form_count > 0:
                logger.info(
                    f"âœ… Form elements found after extended networkidle: {form_count}"
                )
                return True

            # HubSpotç‰¹æœ‰ã®è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
            hubspot_elements = await self.page.evaluate("""
                () => {
                    const hbsptForms = document.querySelectorAll('.hbspt-form').length;
                    const hsInputs = document.querySelectorAll('.hs-input').length;
                    const hsFieldsets = document.querySelectorAll('fieldset.form-columns-1, fieldset.form-columns-2').length;
                    return {hbsptForms, hsInputs, hsFieldsets};
                }
            """)

            total_hubspot = (
                hubspot_elements["hbsptForms"]
                + hubspot_elements["hsInputs"]
                + hubspot_elements["hsFieldsets"]
            )
            if total_hubspot > 0:
                logger.info(
                    f"ğŸ” HubSpot elements found: containers={hubspot_elements['hbsptForms']}, inputs={hubspot_elements['hsInputs']}, fieldsets={hubspot_elements['hsFieldsets']}"
                )
                # HubSpotã‚³ãƒ³ãƒ†ãƒŠãŒã‚ã£ã¦ã‚‚ã€å®Ÿéš›ã®inputè¦ç´ ãŒãªã„å ´åˆã¯ç¶™ç¶šã—ã¦å¾…æ©Ÿ
                if (
                    hubspot_elements["hsInputs"] > 0
                    or hubspot_elements["hsFieldsets"] > 0
                ):
                    logger.info("âœ… HubSpot input elements detected, form is ready")
                    return True
                else:
                    logger.info(
                        "HubSpot containers found but no input elements yet - continuing to Strategy 3..."
                    )

            # inputè¦ç´ ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆformã‚¿ã‚°ç„¡ã—ã®ãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼‰
            input_count = await self.page.evaluate(
                "document.querySelectorAll('input[type=text], input[type=email], textarea, input[type=radio], input[type=checkbox]').length"
            )
            if input_count > 2:  # æœ€ä½3ã¤ã®inputè¦ç´ ãŒå¿…è¦
                logger.info(
                    f"âœ… Multiple input elements found without form tag: {input_count}"
                )
                return True

        except Exception as e:
            logger.debug(f"Extended networkidle wait failed: {e}")

        # æˆ¦ç•¥3: JavaScriptå®Ÿè¡Œå¾…æ©Ÿï¼ˆæ¡ä»¶ä»˜ãå¼·åŒ–ï¼‰
        try:
            logger.info("Strategy 3: JavaScript execution wait...")

            # HubSpotãŒæ¤œå‡ºã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã€ã‚ˆã‚Šå³å¯†ãªå¾…æ©Ÿã‚’è¡Œã†
            has_hubspot = await self.page.evaluate("""
                () => {
                    const scripts = Array.from(document.querySelectorAll('script'));
                    return scripts.some(script => 
                        script.src && script.src.includes('hsforms.net')
                    );
                }
            """)

            if has_hubspot:
                logger.info(
                    "HubSpot detected - applying enhanced form generation wait..."
                )

                # HubSpotå°‚ç”¨ã®æ®µéšçš„å¾…æ©Ÿ
                for attempt in range(4):  # æœ€å¤§4å›è©¦è¡Œï¼ˆ5ç§’x4 = 20ç§’ï¼‰
                    await asyncio.sleep(5)  # 5ç§’å¾…æ©Ÿ

                    # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ãƒã‚§ãƒƒã‚¯
                    form_status = await self.page.evaluate("""
                        () => {
                            const forms = document.querySelectorAll('form').length;
                            const hsFormSpecific = document.querySelectorAll('form[id^="hsForm_"]').length;
                            const hsInputs = document.querySelectorAll('.hs-input').length;
                            const hsFieldsets = document.querySelectorAll('fieldset.form-columns-1, fieldset.form-columns-2').length;
                            const allInputs = document.querySelectorAll('input').length;
                            
                            // HubSpotã‚³ãƒ³ãƒ†ãƒŠå†…ã®formè¦ç´ ã‚‚ãƒã‚§ãƒƒã‚¯
                            let hbsptInnerForms = 0;
                            document.querySelectorAll('.hbspt-form').forEach(container => {
                                hbsptInnerForms += container.querySelectorAll('form').length;
                            });
                            
                            return {forms, hsFormSpecific, hsInputs, hsFieldsets, allInputs, hbsptInnerForms};
                        }
                    """)

                    # iframeå†…ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ãƒã‚§ãƒƒã‚¯
                    iframe_form_count = 0
                    iframe_input_count = 0
                    try:
                        frames = self.page.frames
                        for frame in frames:
                            if (
                                frame != self.page.main_frame
                            ):  # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥å¤–ã‚’ãƒã‚§ãƒƒã‚¯
                                frame_forms = await frame.evaluate(
                                    "document.querySelectorAll('form').length"
                                )
                                frame_inputs = await frame.evaluate(
                                    "document.querySelectorAll('input').length"
                                )
                                iframe_form_count += frame_forms
                                iframe_input_count += frame_inputs
                                if frame_forms > 0:
                                    logger.info(
                                        f"iframe detected forms: {frame_forms} in frame: {frame.url}"
                                    )
                    except Exception as e:
                        logger.debug(f"iframe access error: {e}")

                    total_forms = form_status["forms"] + iframe_form_count
                    total_inputs = form_status["allInputs"] + iframe_input_count

                    logger.info(
                        f"HubSpot attempt {attempt+1}: main_forms={form_status['forms']}, iframe_forms={iframe_form_count}, hsInputs={form_status['hsInputs']}, hsFieldsets={form_status['hsFieldsets']}, total_inputs={total_inputs}"
                    )

                    # æˆåŠŸæ¡ä»¶ï¼šå®Ÿéš›ã®formè¦ç´ ã¾ãŸã¯inputè¦ç´ ãŒååˆ†æ•°å­˜åœ¨
                    if (
                        total_forms > 0
                        or form_status["hsInputs"] > 3
                        or form_status["hsFieldsets"] > 0
                        or total_inputs > 5
                    ):
                        logger.info(
                            f"âœ… HubSpot form elements fully loaded on attempt {attempt+1} (forms: {total_forms}, inputs: {total_inputs})"
                        )
                        return True

                # HubSpotç”¨ã®iframeå‡¦ç†
                iframe_count = await self.page.evaluate(
                    "document.querySelectorAll('iframe.hs-form-iframe').length"
                )
                if iframe_count > 0:
                    logger.info(
                        f"HubSpot iframe detected: {iframe_count}, applying additional wait..."
                    )
                    await asyncio.sleep(3)  # iframeèª­ã¿è¾¼ã¿ç”¨ã®è¿½åŠ å¾…æ©Ÿ

            else:
                # é€šå¸¸ã®ãƒ•ã‚©ãƒ¼ãƒ ç”¨ã®è»½é‡ãªå¾…æ©Ÿï¼ˆæ—¢å­˜å‡¦ç†ã‚’ç¶­æŒï¼‰
                await self.page.wait_for_function(
                    """() => {
                        const forms = document.querySelectorAll('form');
                        const inputs = document.querySelectorAll('input[type="text"], input[type="email"], textarea');
                        return forms.length > 0 || inputs.length > 3;
                    }""",
                    timeout=8000,
                )

            # æœ€çµ‚çš„ãªè¦ç´ ãƒã‚§ãƒƒã‚¯
            final_check = await self.page.evaluate("""
                () => {
                    const forms = document.querySelectorAll('form').length;
                    const hbsptForms = document.querySelectorAll('.hbspt-form').length;
                    const inputs = document.querySelectorAll('input').length;
                    const textareas = document.querySelectorAll('textarea').length;
                    const selects = document.querySelectorAll('select').length;
                    const hsInputs = document.querySelectorAll('.hs-input').length;
                    return {forms, hbsptForms, inputs, textareas, selects, hsInputs};
                }
            """)

            total_elements = (
                final_check["forms"]
                + final_check["inputs"]
                + final_check["textareas"]
                + final_check["selects"]
            )
            logger.info(
                f"JavaScript wait results: forms={final_check['forms']}, hbspt={final_check['hbsptForms']}, inputs={final_check['inputs']}, hsInputs={final_check['hsInputs']}, textareas={final_check['textareas']}, selects={final_check['selects']}"
            )

            if total_elements > 0 or final_check["hsInputs"] > 0:
                logger.info(
                    f"âœ… Form elements found via JavaScript wait: {total_elements} total (hsInputs: {final_check['hsInputs']})"
                )
                return True

        except Exception as e:
            logger.debug(f"JavaScript execution wait failed: {e}")

        # æˆ¦ç•¥4: ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒˆãƒªã‚¬ãƒ¼ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
        try:
            logger.info("Strategy 4: Scroll trigger...")

            # ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦é…å»¶èª­ã¿è¾¼ã¿ã‚’ãƒˆãƒªã‚¬ãƒ¼
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(2)
            await self.page.evaluate("window.scrollTo(0, 0)")
            await asyncio.sleep(2)

            # æœ€çµ‚ãƒã‚§ãƒƒã‚¯
            form_count = await self.page.evaluate(
                "document.querySelectorAll('form').length"
            )
            input_count = await self.page.evaluate(
                "document.querySelectorAll('input').length"
            )

            if form_count > 0 or input_count > 0:
                logger.info(
                    f"âœ… Elements found after scroll: forms={form_count}, inputs={input_count}"
                )
                return True

        except Exception as e:
            logger.debug(f"Scroll trigger failed: {e}")

        logger.warning(
            "âš ï¸ No form elements found after all dynamic strategies (including HubSpot)"
        )
        return False

    async def _analyze_iframes(self) -> Tuple[str, Optional[Any]]:
        """iframeå†…ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã‚’æŠ½å‡ºã—ã€RuleBasedAnalyzerç”¨ã®target_frameã‚‚æ±ºå®šï¼ˆçµ±åˆç‰ˆï¼‰"""
        iframe_contents = []
        iframe_count = 0
        target_frame = None

        try:
            frames = self.page.frames
            for frame in frames:
                if frame != self.page.main_frame:  # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥å¤–ã‚’ãƒã‚§ãƒƒã‚¯
                    try:
                        # iframeå†…ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ ã‚’å–å¾—
                        frame_content = await frame.content()

                        # å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯
                        frame_forms = await frame.query_selector_all("form")
                        has_forms = len(frame_forms) > 0

                        if not HAS_BEAUTIFULSOUP:
                            # BeautifulSoupãŒãªã„å ´åˆã®åŸºæœ¬æŠ½å‡º
                            if "<form" in frame_content.lower():
                                iframe_count += 1
                                iframe_contents.append(
                                    f"<!-- iframe {iframe_count} Content from {frame.url} -->\n{frame_content}\n"
                                )
                                if not target_frame and has_forms:
                                    target_frame = frame
                        else:
                            # BeautifulSoupã‚’ä½¿ç”¨ã—ãŸæŠ½å‡º
                            soup = BeautifulSoup(frame_content, "html.parser")
                            forms = soup.find_all("form")

                            if forms:
                                iframe_count += 1
                                iframe_contents.append(
                                    f"<!-- iframe {iframe_count} Forms from {frame.url} -->\n"
                                )
                                for i, form in enumerate(forms):
                                    iframe_contents.append(
                                        f"<!-- iframe {iframe_count} Form {i+1} -->\n{str(form)}\n"
                                    )

                                logger.info(
                                    f"Extracted {len(forms)} form(s) from iframe: {frame.url}"
                                )

                                # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸãƒ•ã‚©ãƒ¼ãƒ ä»˜ãiframeã‚’target_frameã«è¨­å®š
                                if not target_frame and has_forms:
                                    target_frame = frame

                            # iframeå†…ã®HubSpotè¦ç´ ã‚‚æŠ½å‡º
                            hubspot_elements = soup.find_all(
                                ["input", "textarea", "fieldset"],
                                class_=lambda x: x
                                and ("hs-" in str(x) if x else False),
                            )
                            if hubspot_elements and not forms:
                                # ãƒ•ã‚©ãƒ¼ãƒ ã‚¿ã‚°ãŒãªã„ãŒHubSpotè¦ç´ ãŒã‚ã‚‹å ´åˆ
                                iframe_count += 1
                                body = soup.find("body") or soup
                                iframe_contents.append(
                                    f"<!-- iframe {iframe_count} HubSpot Elements from {frame.url} -->\n{str(body)}\n"
                                )
                                logger.info(
                                    f"Extracted HubSpot elements from iframe: {frame.url}"
                                )

                                # HubSpotè¦ç´ ãŒã‚ã£ã¦ãƒ•ã‚©ãƒ¼ãƒ ãŒå®Ÿéš›ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯target_frameã«è¨­å®š
                                if not target_frame and has_forms:
                                    target_frame = frame

                    except Exception as e:
                        logger.debug(f"Failed to extract from iframe {frame.url}: {e}")
                        continue

        except Exception as e:
            logger.debug(f"iframe extraction failed: {e}")

        iframe_content_str = ""
        if iframe_contents:
            logger.info(f"Successfully extracted content from {iframe_count} iframe(s)")
            iframe_content_str = "\n".join(iframe_contents)

        if target_frame:
            logger.info(
                f"ğŸ“‹ Target iframe found for analysis: {len(await target_frame.query_selector_all('form'))} forms found"
            )

        return iframe_content_str, target_frame

    # æ”¹å–„ææ¡ˆãƒ¡ã‚½ãƒƒãƒ‰ã¯å‰Šé™¤ï¼ˆfield-mapping-coderãŒè‡ªå‹•åˆ¤æ–­ï¼‰

    def _extract_form_content(self, page_html: str) -> str:
        """
        HTMLãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‹ã‚‰<form>è¦ç´ ã®å†…å®¹ã®ã¿ã‚’æŠ½å‡ºï¼ˆHubSpotå¯¾å¿œå¼·åŒ–ï¼‰

        Args:
            page_html: å®Œå…¨ãªãƒšãƒ¼ã‚¸HTML

        Returns:
            formè¦ç´ ã®ã¿ã‚’å«ã‚€HTMLæ–‡å­—åˆ—
        """
        if not HAS_BEAUTIFULSOUP:
            # BeautifulSoupãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - åŸºæœ¬çš„ãª<form>æŠ½å‡º
            logger.warning("BeautifulSoup not available, using basic form extraction")
            return self._extract_form_basic(page_html)

        try:
            soup = BeautifulSoup(page_html, "html.parser")
            form_elements = soup.find_all("form")

            # HubSpotãƒ•ã‚©ãƒ¼ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚‚ãƒã‚§ãƒƒã‚¯
            hubspot_containers = soup.find_all(
                ["div"], class_=["hbspt-form", "hs-form"]
            )
            hubspot_forms_by_id = soup.find_all(
                "div", id=lambda x: x and x.startswith("hbspt-form-")
            )

            # æŠ½å‡ºã•ã‚Œã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            form_contents = []

            # é€šå¸¸ã®formè¦ç´ ã‚’æŠ½å‡º
            if form_elements:
                for i, form in enumerate(form_elements):
                    form_contents.append(f"<!-- Form {i+1} -->\n{str(form)}\n")
                logger.info(
                    f"Extracted {len(form_elements)} standard form element(s) from page source"
                )

            # HubSpotãƒ•ã‚©ãƒ¼ãƒ ã‚³ãƒ³ãƒ†ãƒŠã‚’æŠ½å‡º
            hubspot_count = 0
            for container in hubspot_containers + hubspot_forms_by_id:
                if container not in [
                    elem.find_parent(["div"], class_=["hbspt-form", "hs-form"])
                    for elem in form_elements
                    if elem.find_parent(["div"], class_=["hbspt-form", "hs-form"])
                ]:
                    hubspot_count += 1
                    form_contents.append(
                        f"<!-- HubSpot Container {hubspot_count} -->\n{str(container)}\n"
                    )

            if hubspot_count > 0:
                logger.info(
                    f"Extracted {hubspot_count} HubSpot form container(s) from page source"
                )

            # ä½•ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®å‡¦ç†
            if not form_contents:
                # inputè¦ç´ ãŒå¤šæ•°ã‚ã‚‹å ´åˆã€bodyå…¨ä½“ã‚’æŠ½å‡ºï¼ˆHubSpotæœªæ¤œå‡ºã‚±ãƒ¼ã‚¹å¯¾å¿œï¼‰
                inputs = soup.find_all(["input", "textarea", "select"])
                if len(inputs) > 3:
                    logger.warning(
                        f"No form containers found, but {len(inputs)} input elements detected - extracting body"
                    )
                    body = soup.find("body")
                    if body:
                        return f"<!-- Full body content (multiple inputs detected) -->\n{str(body)}\n"

                logger.warning("No <form> elements or HubSpot containers found in page")
                return "<!-- No form elements found -->\n"

            extracted_html = "\n".join(form_contents)
            return extracted_html

        except Exception as e:
            logger.error(f"Form extraction failed: {e}")
            return self._extract_form_basic(page_html)

    def _extract_form_basic(self, page_html: str) -> str:
        """
        BeautifulSoupæœªä½¿ç”¨æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªformæŠ½å‡º

        Args:
            page_html: å®Œå…¨ãªãƒšãƒ¼ã‚¸HTML

        Returns:
            formè¦ç´ ã®ã¿ã‚’å«ã‚€HTMLæ–‡å­—åˆ—ï¼ˆåŸºæœ¬æŠ½å‡ºç‰ˆï¼‰
        """
        import re

        # åŸºæœ¬çš„ãªæ­£è¦è¡¨ç¾ã§formè¦ç´ ã‚’æŠ½å‡º
        form_pattern = re.compile(r"<form[^>]*>.*?</form>", re.DOTALL | re.IGNORECASE)
        forms = form_pattern.findall(page_html)

        if not forms:
            logger.warning("No forms found with basic extraction")
            return "<!-- No form elements found with basic extraction -->\n"

        logger.info(f"Basic extraction found {len(forms)} form(s)")
        return "\n\n".join(
            f"<!-- Form {i+1} (basic extraction) -->\n{form}"
            for i, form in enumerate(forms)
        )

    async def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— - å¼·åŒ–ç‰ˆ"""
        cleanup_errors = []

        # ãƒšãƒ¼ã‚¸ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.page:
            try:
                logger.debug("Closing page...")
                await asyncio.wait_for(self.page.close(), timeout=5.0)
                self.page = None
            except Exception as e:
                cleanup_errors.append(f"Page cleanup error: {e}")
                self.page = None  # å¼·åˆ¶çš„ã«ã‚¯ãƒªã‚¢

        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.browser:
            try:
                logger.debug("Closing browser...")
                await asyncio.wait_for(self.browser.close(), timeout=10.0)
                self.browser = None
            except Exception as e:
                cleanup_errors.append(f"Browser cleanup error: {e}")
                self.browser = None  # å¼·åˆ¶çš„ã«ã‚¯ãƒªã‚¢

        # Playwrightã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.playwright:
            try:
                logger.debug("Stopping playwright...")
                await asyncio.wait_for(self.playwright.stop(), timeout=5.0)
                self.playwright = None
            except Exception as e:
                cleanup_errors.append(f"Playwright cleanup error: {e}")
                self.playwright = None  # å¼·åˆ¶çš„ã«ã‚¯ãƒªã‚¢

        # åˆæœŸåŒ–ãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆ
        self._initialized = False

        # ãƒ¡ãƒ¢ãƒªå¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        try:
            import gc

            gc.collect()
            logger.debug("Forced garbage collection completed")
        except Exception:
            pass

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çµæœãƒ¬ãƒãƒ¼ãƒˆ
        if cleanup_errors:
            logger.warning(f"âš ï¸ Cleanup completed with {len(cleanup_errors)} errors:")
            for error in cleanup_errors:
                logger.warning(f"   - {error}")
        else:
            logger.info("âœ… All resources cleaned up successfully")

        logger.info(f"ğŸ—‚ï¸ Test files: {self.temp_dir}")

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ­ã‚°ï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        try:
            import psutil

            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            logger.info(f"ğŸ’¾ Current memory usage: {memory_mb:.1f} MB")
        except ImportError:
            pass
        except Exception:
            pass


"""é€£ç¶šå®Ÿè¡Œ(--count)ã¯å»ƒæ­¢ã€‚å˜ä¸€å®Ÿè¡Œã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã€‚"""


# é•·ã‚ã®å‹•çš„ç”Ÿæˆãƒ•ã‚©ãƒ¼ãƒ ã«ã‚‚å¯¾å¿œã™ã‚‹ãŸã‚å»¶é•·ï¼ˆå˜ç™ºãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œã®ãŸã‚è¨±å®¹ï¼‰ã€‚
DEFAULT_TEST_TIMEOUT_SECONDS = 240  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å˜ä¸€å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ4åˆ†ï¼‰


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Field Mapping Algorithm Testing Tool (single-run only)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python test_field_mapping_analyzer.py                    # Single random test
  python test_field_mapping_analyzer.py --company-id 12345 # Test specific company
""",
    )

    parser.add_argument("--company-id", type=int, help="Specific company ID to test")
    # --count ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯å»ƒæ­¢
    parser.add_argument(
        "--verbose", action="store_true", help="Show normal logs (summary filter off)"
    )
    parser.add_argument("--debug", action="store_true", help="Show debug logs")

    args = parser.parse_args()

    # ãƒ­ã‚°æ§‹æˆï¼ˆquietãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    configure_logging(verbose=args.verbose, debug=args.debug)

    # å˜ä¸€ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã®ã¿å¯¾å¿œ
    try:
        async with FieldMappingAnalyzer() as analyzer:
            try:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œï¼ˆå¼•æ•°ãªã—ï¼‰ã¯å…¨ä½“ã§2åˆ†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                success = await asyncio.wait_for(
                    analyzer.run_single_test(args.company_id),
                    timeout=DEFAULT_TEST_TIMEOUT_SECONDS,
                )
            except asyncio.TimeoutError:
                logger.error(
                    f"â±ï¸ Test timed out after {DEFAULT_TEST_TIMEOUT_SECONDS} seconds"
                )
                success = False

            if success:
                logger.info("ğŸ¯ Field mapping analysis completed successfully!")
            else:
                logger.error("âŒ Field mapping analysis failed")

    except Exception as e:
        logger.error(f"âŒ Analysis failed: {e}")
        import gc

        gc.collect()  # ä¾‹å¤–æ™‚ã‚‚ç¢ºå®Ÿã«ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—


if __name__ == "__main__":
    asyncio.run(main())
